# 1 SQLé€ŸæˆåŠ å¼º

**sqlï¼Œ æ˜¯ä¸€é—¨åŸºäºå…³ç³»ä»£æ•°çš„é¢å‘é›†åˆçš„è¯­è¨€**



## 1.1 **sqlçš„æ ¸å¿ƒå…³é”®å­—**

### **ğŸ” select**&#x20;

è¿ç®—è¡¨è¾¾å¼

```sql
select  id,name
select  id+10, name'Mr'
select  greatest(id,20),upper(name)
select  10,id,namge,age+20,'ok'
```

| id | name |
| -- | ---- |
| 1  | zs   |
| 2  | ls   |

```sql
select id,name,id,name,id+name,10,2000,upper(name),age


for(Person p: list){
    sout(p.id,p.name,p.id,p.name,p.id+p.name,10,2000,p.name.toUpperCase());
}

```





### ğŸ” from

```sql
from è¡¨

from (select  ....  from ...)

from ( è¡¨1 join  è¡¨2  on æ¡ä»¶)
```





### ğŸ” join

| id | name | age |
| -- | ---- | --- |
| 1  | aa   | 18  |
| 2  | bb   | 28  |
| 3  | cc   | 38  |
| 4  | dd   | 48  |

| uid | address | salary |
| --- | ------- | ------ |
| 1   | bj      | 1000   |
| 2   | bj      | 3000   |
| 2   | bj      | 2000   |
| 4   | sh      | 3000   |
| 5   | sh      | 4000   |



**t1 join t2 on t1.id=t2.uid  &#x20;**

```sql
1,aa,18   1,bj,1000
2,bb,28   2,bj,3000
2,bb,28   2,bj,2000
4,dd,48   4,sh,3000
```



**t1 left join t2 on t1.id=t2.uid**

```sql
1,aa,18   1,bj,1000
2,bb,28   2,bj,3000
2,bb,28   2,bj,2000
3,cc,38   \N,\N,\N
4,dd,48   4,sh,3000
```



**t1 right join t2 on t1.id=t2.uid**

```sql
1,aa,18   1,bj,1000
2,bb,28   2,bj,3000
2,bb,28   2,bj,2000
4,dd,48   4,sh,3000
\n,\n,\n  5,sh,4000
```



**t1 full join t2 on t1.id=t2.uid**

```sql
1,aa,18     1,bj,1000
2,bb,28     2,bj,3000
2,bb,28     2,bj,2000
3,cc,38     \n,\n,\n
4,dd,48     4,sh,3000
\n,\n,\n    5,sh,4000
```





### ğŸ” where

where åé¢çš„è¡¨è¾¾å¼ï¼Œå…¶å®å°±æ˜¯å¯¹fromè¯»åˆ°çš„æ•°æ®è¿›è¡Œè¿‡æ»¤

```sql
where å¸ƒå°”è¡¨è¾¾å¼

where 1=1
where 1>2
where id>age
where id>2
where id>1 and age>28
```







## 1.2 sqlè¿ç®—æ¨¡å¼

### 1 é€è¡Œè¿ç®—æ¨¡å¼

![](images/diagram.png)

> é€è¡Œè¿ç®—æ¨¡å¼ä¸‹ï¼Œè¡¨è¾¾å¼å¯ä»¥æ˜¯ï¼š
>
> å­—æ®µå
>
> å­—æ®µè¿ç®—è¡¨è¾¾å¼ï¼šç®—æœ¯è¿ç®—ã€å¸ƒå°”è¿ç®—ç­‰
>
> å‡½æ•°è°ƒç”¨ï¼šæ ‡é‡å‡½æ•°ï¼ˆscalarå‡½æ•°ï¼‰\[è¿›ä¸€è¡Œï¼Œå‡ºä¸€è¡Œ]
>
> \-- å‡½æ•°é€šå¸¸æœ‰ï¼šæ ‡é‡å‡½æ•°ã€ èšåˆå‡½æ•°\[è¿›å¤šè¡Œï¼Œå‡ºä¸€è¡Œ] ã€ è¡¨ç”Ÿæˆå‡½æ•°\[è¿›Nè¡ŒMåˆ—ï¼Œå‡º Xè¡ŒYåˆ—]







### 2 åˆ†ç»„èšåˆæ¨¡å¼

![](images/diagram-1.png)

> ç‰¹ç‚¹ï¼š æ¯ä¸€ä¸ªç»„ï¼Œç»“æœåªä¼šæœ‰ä¸€è¡Œ
>
> selectä¸­çš„è¡¨è¾¾å¼ï¼š   åˆ†ç»„keyï¼Œèšåˆå‡½æ•°ï¼Œå¸¸é‡
>
> select
>
> id,
>
> upper(**max**(name))   -- è¿™é‡Œè™½ç„¶upperæ˜¯ä¸€ä¸ªæ ‡é‡å‡½æ•°ï¼Œä½†æ˜¯å®ƒçš„è¾“å…¥æ˜¯ä¸€ä¸ªèšåˆå‡½æ•°çš„ç»“æœ
>
> From t&#x20;
>
> Group by id ;





### 3 çª—å£æ¨¡å¼

#### ğŸ” çª—å£è¿ç®—çš„åŸºæœ¬ç‰¹æ€§

![](images/diagram-2.png)

#### **ğŸ” çª—å£å‡½æ•°çš„è¯­æ³•ç»“æ„**

```java
èšåˆå‡½æ•°(å­—æ®µ)  over(partition by å­—æ®µ..   order by å­—æ®µ...   çª—å£å®šä¹‰ )

partition by  ï¼šåˆ†åŒºå®šä¹‰ï¼› ä¸åŒåˆ†åŒºçš„æ•°æ®äº’ä¸å¹²æ‰°ï¼Œå„è‡ªè®¡ç®—
order by ï¼šæ’åºå®šä¹‰ï¼›  å„åˆ†åŒºå†…å„è‡ªæ’åº 
```



#### **ğŸ” çª—å£å®šä¹‰è¯­æ³•&#x20;**

**- æŒ‰è¡ŒæŒ‡å®šçª—å£ï¼ˆwindow frameï¼‰ ï¼š &#x20;**&#xA;**\[rows between ... preceding and ... following]**
\* rows between 5 preceding and 3 following  :  çª—å£æ¡†ä½çš„å½“å‰è®¡ç®—è¡Œçš„å‰5è¡Œï¼Œåˆ°å½“å‰è®¡ç®—è¡Œçš„å5è¡Œ
\* rows between unbounded **preceding&#x20;**&#x61;nd 5 **following** :ä»åˆ†åŒºçš„æœ€å‰æ¡†åˆ°å½“å‰è®¡ç®—è¡Œçš„å5è¡Œæˆªæ­¢
\* rows betwwen unbounded preceding and unbounded following : æ¡†ä½æ•´ä¸ªåˆ†åŒº
\* rows between unbounded preceding an&#x64;**&#x20;current row**




**- æŒ‰æ’åæŒ‡å®šçª—å£ï¼ˆwindow frameï¼‰ ï¼š &#x20;**&#xA;**\[range between ... preceding and ... following]**
\* range between 2 preceding and 1 following : çª—å£æ¡†ä½çš„æ˜¯åˆ†åŒºä¸­ï¼Œå½“å‰è®¡ç®—è¡Œçš„å‰2åçš„æ‰€æœ‰æ•°æ®å’Œå½“å‰è¡Œæ‰€å±æ’åçš„æ‰€æœ‰æ•°æ®ï¼Œå’Œå½“å‰è¡Œæ’åçš„å1åçš„æ‰€æœ‰æ•°æ®

&#x20;\[ å½“å‰è¡Œæ‰€å±åæ¬¡çš„ å‰2å  åˆ° å1åï¼Œ æ¯ä¸ª**åæ¬¡å¯¹åº”çš„æ‰€æœ‰æ•°æ®**éƒ½è¿›å…¥çª—å£ ]&#x20;


![](images/diagram-3.png)





#### ğŸ” å„ç±»å®šä¹‰ç¼ºå¤±æ—¶çš„é»˜è®¤å€¼

* **æ²¡æœ‰æŒ‡å®šåˆ†åŒºå®šä¹‰**

**partition by 0&#x20;**ï¼š  ç›¸å½“äºæ•´ä¸ªè¡¨æ˜¯ä¸€ä¸ªåˆ†åŒº&#x20;



* **æ²¡æœ‰æŒ‡å®šçª—å£å®šä¹‰**

  * æœ‰æŒ‡å®šæ’åº  ï¼š   **range&#x20;**&#x62;etween  æœ€å‰ åˆ°  å½“å‰

  * æ— æŒ‡å®šæ’åº  ï¼š   **rows&#x20;**&#x62;etween   æœ€å‰  åˆ°  æœ€å &#x20;

  * æœ‰æŒ‡å®šæ’åºä¸”rowsï¼ŒæŒ‰ä½ çš„rows



**æºç é€»è¾‘ï¼š WindowingSpecç±»çš„ effectiveWindowFrame()æ–¹æ³•ä¸­**

![](images/image-2.png)





### 4 å£¹ä¸ªsqlå¤šä¸ªçª—å£

```sql
select
    id,
    mth,
    shop,
    amt,
    row_number() over(partition by shop order by amt desc) as rn ,
    sum(amt) over(partition by mth order by id,shop)  as accu
from ds7
```

å…¶å®ï¼Œä¸Šé¢çš„è¯­å¥ï¼Œç­‰ä»·äº

```sql
with tmp as (
select
    id,
    mth,
    shop,
    amt,
    row_number() over(partition by shop order by amt desc) as rn 
from ds7
)
select
    id,
    mth,
    shop,
    amt,
    rn ,
    sum(amt) over(partition by mth order by id,shop)  as accu
from tmp 
```



> å¦‚æœä¸€ä¸ªsqlä¸­ï¼Œå¤šä¸ªçª—å£ä¸­çš„partition byæ˜¯åŒä¸€ä¸ªå­—æ®µ
>
> åˆ™hiveä¸­æœ‰ä¸€ä¸ª **hive.optimize.correlation ä¼˜åŒ–æœºåˆ¶ï¼Œå¯ä»¥æŠŠå¤šä¸ªçª—å£è®¡ç®—åˆå¹¶æˆä¸€æ¬¡shuffle**













## 1.3 sqlçš„æ‰§è¡Œé¡ºåº

![](images/diagram-4.png)





https://cwiki.apache.org/confluence/display/Hive/LanguageManual













# 2 DDL æ•°æ®å®šä¹‰

## 2.1 DDLæ“ä½œæ¦‚è§ˆ

* **åˆ›å»ºï¼š** CREATE DATABASE/SCHEMA, TABLE, VIEW, FUNCTION, INDEX

* **åˆ é™¤ï¼š&#x20;**&#x44;ROP DATABASE/SCHEMA, TABLE, VIEW, INDEX

* **æˆªæ–­ï¼š** TRUNCATE TABLE

* **ä¿®æ”¹ï¼š&#x20;**&#x41;LTER DATABASE/SCHEMA, TABLE, VIEW

* **ä¿®å¤ï¼š&#x20;**&#x4D;SCK REPAIR TABLE (or ALTER TABLE RECOVER PARTITIONS)

* **å±•ç¤ºï¼š&#x20;**&#x53;HOW DATABASES/SCHEMAS, TABLES, TBLPROPERTIES, VIEWS, PARTITIONS, FUNCTIONS, INDEX\[ES], COLUMNS, CREATE TABLE

* **æè¿°ï¼š&#x20;**&#x44;ESCRIBE DATABASE/SCHEMA, table\_name, view\_name, materialized\_view\_name



## 2.2 å»ºè¡¨è¯­æ³•

```sql
CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name    -- (Note: TEMPORARY available in Hive 0.14.0 and later)
  [(col_name data_type [column_constraint_specification] [COMMENT col_comment], ... [constraint_specification])]
  [COMMENT table_comment]
  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]
  [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
  [SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 0.10.0 and later)]
     ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)
     [STORED AS DIRECTORIES]
  [
   [ROW FORMAT row_format] 
   [STORED AS file_format]
     | STORED BY 'storage.handler.class.name' [WITH SERDEPROPERTIES (...)]  -- (Note: Available in Hive 0.6.0 and later)
  ]
  [LOCATION hdfs_path]
  [TBLPROPERTIES (property_name=property_value, ...)]   -- (Note: Available in Hive 0.6.0 and later)
  [AS select_statement];   -- (Note: Available in Hive 0.5.0 and later; not supported for external tables)
```



TEMPORARYï¼š ä¸´æ—¶è¡¨

> åªåœ¨å½“å‰ä¼šè¯ä¸­å­˜åœ¨çš„è¡¨ï¼›ä¼šè¯ç»“æŸï¼Œè¯¥è¡¨ä¼šè¢«è‡ªåŠ¨åˆ é™¤



EXTERNALï¼š è¡¨ç¤ºå¤–éƒ¨è¡¨

> å¤–éƒ¨è¡¨æ˜¯ç›¸å¯¹äº â€œå†…éƒ¨è¡¨â€çš„ä¸€ä¸ªæ¦‚å¿µ
>
> å†…éƒ¨è¡¨ä¹Ÿæœ‰å…³é”®å­—ï¼šMANAGEDï¼ˆé»˜è®¤å°±æ˜¯å®ƒï¼‰
>
> å¤–éƒ¨è¡¨å’Œå†…éƒ¨è¡¨çš„æœ€å¤§åŒºåˆ«ï¼š
>
> * drop ä¸€ä¸ªè¡¨çš„æ—¶å€™
>
>   * å¤–éƒ¨è¡¨é»˜è®¤æ˜¯ä¸ä¼šè¢«åˆ é™¤æ•°æ®çš„ï¼›è€Œåªæ˜¯ä»å…ƒæ•°æ®ä¸­æ¸…é™¤ï¼›
>
>   * è€Œå†…éƒ¨è¡¨åˆ™å…ƒæ•°æ®å’Œæ•°æ®å­˜å‚¨éƒ½ä¼šè¢«åˆ é™¤ï¼›
>
> * è¿˜æœ‰ä¸€äº›åŸºäºACIDçš„æœºåˆ¶çš„åŠŸèƒ½ï¼Œåªèƒ½é’ˆå¯¹å†…éƒ¨è¡¨ï¼›





* å­—æ®µåå’Œå­—æ®µç±»å‹ï¼Œæ³¨é‡Š

```sql
create external table db2.t_some(
    id   int   comment 'ç”¨æˆ·ID',
    name string,   -- ç”¨æˆ·å§“å

)
COMMENT  'è¿™æ˜¯ä¸€ä¸ªç”¨æˆ·ä¿¡æ¯è¡¨'

```





## 2.3 åˆ†åŒºè¡¨ä½¿ç”¨

* åœ¨hiveä¸­ï¼Œä¸€ä¸ªè¡¨ï¼Œå¯ä»¥å®šä¹‰æˆåˆ†åŒºè¡¨

* **åˆ†åŒºå¯¹åº”è¡¨å­˜å‚¨ç›®å½•ä¸­çš„å­ç›®å½•**

* åˆ†åŒºè¡¨çš„æ„ä¹‰ä½•åœ¨ï¼š æŸ¥è¯¢æ—¶å¯ä»¥æŒ‡å®šæŸä¸ªæˆ–æŸå‡ ä¸ªåˆ†åŒºæ¥æŸ¥è¯¢ï¼›å¯ä»¥å‡å°‘æ•°æ®æ‰«æçš„èŒƒå›´ï¼›

* è¯­æ³•å°ç»†èŠ‚ï¼š

  * è¡¨å®šä¹‰æ—¶ï¼Œåˆ†åŒºå­—æ®µåä¸èƒ½è·Ÿè¡¨ç»“æ„ä¸­å·²å­˜åœ¨çš„å­—æ®µåé‡å¤ï¼ˆæŸ¥è¯¢æ—¶ä¸€å®šä¼šäº§ç”Ÿæ­§ä¹‰ï¼Œæ‰€ä»¥ä¸å…è®¸ï¼‰

  * è¡¨å®šä¹‰æ—¶ï¼Œåˆ†åŒºå¯ä»¥æŒ‡å®šå¤šçº§



### **åˆ†åŒºå®šä¹‰è¯­æ³•**

```sql
PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)
```





### åˆ†åŒºè¡¨çš„å®šä¹‰å’Œæ’å…¥æ•°æ®å’ŒæŸ¥è¯¢æ•°æ®

```sql
drop table if exists event_log;
create table event_log(
   device_id  string,
   user_name  string,
   event_time bigint,
   province   string
)
PARTITIONED BY (dt STRING)
;



drop table if exists event_log_2;
create table event_log_2(
   device_id  string,
   user_name  string,
   event_time bigint,
   province string
)
PARTITIONED BY (p STRING)
;

insert into table event_log_2 PARTITION(p='JX') values ('d01','u01','1235','æ±Ÿè¥¿çœ');
insert into table event_log_2 PARTITION(p='JX') values ('d02','u02','1444','æ±Ÿè¥¿çœ'),('d03','u03','1555','æ±Ÿè¥¿çœ');


insert into table event_log_2 PARTITION(p='å±±ä¸œçœ') values 
('d04','u04','1235','å±±ä¸œçœ'),
('d05','u05','1444','å±±ä¸œçœ'),
('d06','u06','1555','å±±ä¸œçœ')
;



drop table if exists event_log_3;
create table event_log_3(
   device_id  string,
   user_name  string,
   event_time bigint,
   province string
)
PARTITIONED BY (dt STRING, p STRING)
;


-- å¾€åˆ†åŒºè¡¨ä¸­ï¼Œæ’å…¥æ•°æ®ï¼Œä¸ç®¡ç”¨ä½•ç§æ–¹å¼ï¼Œéƒ½æ˜¯è¦æŒ‡å®šç›®æ ‡åˆ†åŒº
insert into table event_log_3 PARTITION(dt='20240903',p='JX') values ('d01','u02','1444','æ±Ÿè¥¿çœ'),('d02','u03','1555','æ±Ÿè¥¿çœ');
insert into table event_log_3 PARTITION(dt='20240903',p='SH') values ('d03','u02','1444','ä¸Šæµ·å¸‚'),('d04','u03','1555','ä¸Šæµ·å¸‚');
insert into table event_log_3 PARTITION(dt='20240904',p='SH') values ('d05','u02','1444','ä¸Šæµ·å¸‚'),('d06','u03','1555','ä¸Šæµ·å¸‚');

load data inpath '/some/data/*' into table event_log_3 PARTITION(dt='20240904',p='SH');

insert into table event_log_3 PARTITION(dt='20240904',p='SH')
select .... from ....



--  æŸ¥è¯¢æŒ‡å®šåˆ†åŒº  : 3å·çš„æ±Ÿè¥¿  å’Œ  4å·çš„ä¸Šæµ·  
select
province,
count(distinct device_id) as cnt

from event_log_3 
where  (dt='20240903' and p='JX' ) OR (dt='20240904' and p='SH')
GROUP BY province
;


```





### ç»™è¡¨å¢åŠ åˆ†åŒº

* å¾€åˆ†åŒºè¡¨ä¸­æ’å…¥æ•°æ®ï¼ŒæŒ‡å®šåˆ†åŒºï¼Œå¦‚æœç›®æ ‡åˆ†åŒºä¸å­˜åœ¨ï¼Œhiveä¼šè‡ªåŠ¨æ–°å»ºåˆ†åŒºï¼›

* è¿˜æœ‰ä¸“é—¨çš„å¢åŠ åˆ†åŒºçš„è¯­æ³• : ALTER TABLE  xxx  ADD PARTITION(x=y)&#x20;

```sql
-- ä¸ºè¡¨å¢åŠ ä¸€ä¸ªæ–°çš„ç©ºåˆ†åŒº
ALTER TABLE event_log ADD PARTITION(dt='20240905');   -- é»˜è®¤ä½ç½®ï¼š è¡¨ç›®å½•/dt=20240905/

-- ä¸ºè¡¨å¢åŠ ä¸€ä¸ªåˆ†åŒºï¼Œå¹¶æŒ‡å®šåˆ†åŒºçš„å­˜å‚¨ç›®å½•
ALTER TABLE event_log ADD PARTITION(dt='20240906') LOCATION '/aaa/bbb';   -- æŒ‡å®šè·¯å¾„


select * from event_log where dt='20240906';  -- ç©ºç›®å½•ï¼Œæ— æ•°æ®

-- å‡è®¾å·²å­˜åœ¨ç›®å½• ï¼Œå¹¶ä¸”ç›®å½•ä¸­å·²å­˜åœ¨æ•°æ®
hdfs dfs -mkdir /somedata/2024-09-07/
hdfs dfs -put some.txt /somedata/2024-09-07/
-- ç„¶åä¸ºè¡¨æ–°å»ºåˆ†åŒºï¼Œå¹¶æŒ‡å®šåˆ†åŒºå­˜å‚¨è·¯å¾„ä¸ºä¸Šé¢çš„æ–‡ä»¶å¤¹ï¼Œåˆ™è¯¥æ–°åˆ†åŒºç›´æ¥å°±æ‹¥æœ‰äº†æ•°æ®
ALTER TABLE event_log ADD PARTITION(dt='20240907') LOCATION '/somedata/2024-09-07';



-- æ‰‹åŠ¨ç»™ä¸€ä¸ªè¡¨åˆ›å»ºä¸€ä¸ªåˆ†åŒºç›®å½•ï¼Œhiveæ˜¯å¦è‡ªåŠ¨è¯†åˆ«è¿™ä¸ªåˆ†åŒºï¼Ÿ
hdfs dfs -mkdir /user/hive/warehouse/event_log/dt=20240908
-- è¿™æ ·æ˜¯ä¸ä¼šè¯†åˆ«ï¼Œå› ä¸ºhiveæ²¡æœ‰ä¸ºæ­¤åˆ›å»ºå…ƒæ•°æ®è®°å½•
-- éœ€è¦æ‰‹åŠ¨ç”¨å¦‚ä¸‹å‘½ä»¤å»é©±ä½¿hiveæ£€æŸ¥å¹¶å¢åŠ åˆ†åŒºçš„å…ƒæ•°æ®æ‰èƒ½è¯†åˆ«
MSCK REPAIR TABLE event_log SYNC PARTITIONS;
-- æˆ–
ALTER TABLE event_log ADD PARTITION(dt='20240908');
```







### åˆ é™¤åˆ†åŒº

```sql
-- å¦‚æœæ˜¯å¤–éƒ¨è¡¨ï¼Œé»˜è®¤æƒ…å†µä¸‹åªæ¸…é™¤è¯¥åˆ†åŒºçš„å…ƒæ•°æ®è®°å½•ï¼›ä¸ä¼šåˆ æ•°æ®å­˜å‚¨ç›®å½•
-- å¦‚æœæ˜¯å†…éƒ¨è¡¨ï¼Œåˆ™è¯¥åˆ†åŒºçš„å…ƒæ•°æ®è®°å½•å’Œå¯¹åº”çš„æ•°æ®å­˜å‚¨ç›®å½•ï¼Œéƒ½ä¼šè¢«åˆ é™¤
alter table event_log drop partition(dt='20240908');
```





### åˆ†åŒºä¿¡æ¯

```sql
SHOW PARTITIONS event_log;

DESC FORMATTED event_log PARTITION(dt='20240906');
```





## 2.4 åˆ†æ¡¶è¡¨ä½¿ç”¨

```sql
[CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]
```



**åˆ†æ¡¶è¡¨ä¸­ï¼Œæ•°æ®çš„åˆ†å¸ƒæ˜¯æœ‰è§„å¾‹çš„ï¼š**

* é¦–å…ˆï¼Œæ ¹æ®æŒ‡å®šçš„clustered byå­—æ®µè¿›è¡Œhashæ•£åˆ—ï¼Œæ•£åˆ—åˆ°å¤šä¸ªæ–‡ä»¶ï¼ˆæ¯ä¸ªæ–‡ä»¶å°±æ˜¯ä¸€ä¸ªæ¡¶ï¼‰

* ç„¶åï¼Œæ ¹æ®æŒ‡å®šçš„sorted byå­—æ®µåœ¨æ¯ä¸€ä¸ªæ¡¶ä¸­æ’åº

```sql
drop table if exists member_info;
create table member_info(
    uid int,
    name string,
    age int
)
PARTITIONED BY (dt string)
clustered by (uid) sorted by (age) into 3 BUCKETS
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
;
```



**å‘åˆ†æ¡¶è¡¨ä¸­æ’å…¥æ•°æ®**

> ä¸è¦æ‰‹åŠ¨loadæ•°æ®ï¼Œå› ä¸ºè¿™æ ·å¯èƒ½æ²¡æœ‰æ­£ç¡®åŒ¹é…åˆ†æ¡¶è¡¨çš„æ•°æ®åˆ†å¸ƒè§„å¾‹
>
> è€Œæ˜¯ä½¿ç”¨insert + select æ¥å¾€åˆ†æ¡¶è¡¨ä¸­æ’å…¥æ•°æ®ï¼Œè¿™æ ·ä¼šè‡ªåŠ¨å½¢æˆåˆ†æ¡¶è¡¨å®šä¹‰çš„æ•£åˆ—æœ‰åºæ–‡ä»¶



```sql
create table member_origin(
    uid int,
    name string,
    age int
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
;

-----------------
insert into member_info PARTITION(dt='20240904')
select
uid,
name,
age
from member_origin;


insert into member_info PARTITION(dt='20240905')
select
uid,
name,
age
from member_origin;
```



## 2.5 å€¾æ–œè¡¨ä½¿ç”¨

```sql
  [SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 0.10.0 and later)]
     ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)
     [STORED AS DIRECTORIES]
```

![](images/image.png)



```sql
-- æµ‹è¯•æ•°æ®æºè¡¨
create table t_skew_origin(
    id int ,
    name string,
    event_id string
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
;



-- å€¾æ–œè¡¨
drop table t_skew;
create table t_skew(
    id int ,
    name string,
    event_id string
)

skewed by (id) on (3,5)   
stored as directories     -- å¦‚æœä¸åŠ è¿™ä¸ªï¼Œåˆ™ä¸ä¼šæŠŠå€¾æ–œæ•°æ®å­˜å…¥ä¸“é—¨çš„å­ç›®å½•

ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
;


-- å¾€å€¾æ–œè¡¨ä¸­æ’å…¥æ•°æ®
insert into t_skew
select * from t_skew_origin
```

> å€¾æ–œè¡¨å¦‚æœå¸¦äº†  STORED AS DIRECTORIES  ï¼Œé‚£ä¹ˆæ•°æ®ä¼šåˆ†æˆå¤šä¸ªå­ç›®å½•å­˜æ”¾
>
> å€¾æ–œå€¼çš„ä¸€ä¸ªæˆ–å¤šä¸ªå­ç›®å½•
>
> éå€¾æ–œå€¼çš„å­ç›®å½•
>
>
>
> æ³¨æ„ï¼š åœ¨è¿™ç§å®šä¹‰ä¸‹ï¼ŒæŸ¥è¯¢æ•°æ®éœ€è¦æŠŠå¦‚ä¸‹å‚æ•°è®¾ç½®ä¸ºTRUEï¼Œæ‰èƒ½æŸ¥åˆ°æ•°æ®
>
> set mapreduce.input.fileinputformat.input.dir.recursive=true;



å¦‚æœä¸€ä¸ªè¡¨åœ¨å®šä¹‰æ—¶æ²¡æœ‰å®šä¹‰æˆå€¾æ–œï¼Œåç»­å¯ä»¥ä½¿ç”¨alterå‘½ä»¤æ¥ä¿®æ”¹å€¾æ–œå®šä¹‰

```sql
alter table some_table skew by (id)  on (3,5);
```





## 2.6 æ•°æ®å­˜å‚¨æ ¼å¼

è¡¨çš„æ•°æ®æ ¼å¼çš„ï¼Œå…·ä½“æœ‰ä¸¤å±‚ï¼š

1. ROW FORMAT **è¡Œä¸­çš„å­—æ®µçš„è§£ææ–¹å¼**

> ç”¨SERDEæ¥æŒ‡å®š
>
> row format serde '....'  &#x20;
>
> with serdeproperties('k'='v' , 'k2'='v2')





* STORED AS **å­˜å‚¨æ–‡ä»¶æ ¼å¼ &#x20;**

> ç”¨ INPUTFORMAT  å’Œ OUTPUTFORMAT æ¥æŒ‡å®š:  STORED AS  INPUTFORMAT '.......'    OUTPUTFORMAT '.......'
>
> ä¹Ÿå¯ä»¥ç”¨æ–‡ä»¶ç±»å‹åæ¥æŒ‡å®š   STORED AS PARQUETFILE





* **å®Œæ•´å®šä¹‰ç¤ºä¾‹**

```sql
create table xx(


)
ROW FORMAT   -- æŒ‡å®šè¡Œå†…å­—æ®µè§£ææ–¹å¼
SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'   
WITH SERDEPROPERTIES (                             
  'field.delim'=',',                               
  'serialization.format'=','
) 
                       
STORED AS    -- æŒ‡å®šæ–‡ä»¶æ ¼å¼
INPUTFORMAT                              
  'org.apache.hadoop.mapred.TextInputFormat'       
OUTPUTFORMAT                                       
  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'  
```



* ç”¨æˆ·å‹å¥½å†™æ³•

```sql
create table xx (


)
STORED AS ORC;
```



```sql
STORED AS TEXTFILE   + éœ€è¦æ˜¾å¼æŒ‡å®šSERDE 
STORED AS ORC 
STORED AS PARQUET
STORED AS SEQUENCEFILE
```



å…³äº TEXTFILEæ˜¾å¼æŒ‡å®šSERDE çš„ ç¤ºä¾‹ï¼š

* å­˜æ–‡æœ¬æ–‡ä»¶

* æ–‡æœ¬æ–‡ä»¶ä¸­çš„å†…éƒ¨æ•°æ®æ ¼å¼&#x662F;**ï¼šjson**

```sql
drop table if exists orders;
CREATE TABLE orders(

    order_id  int,
    amount double,
    order_date date
)
PARTITIONED BY (dt string)
row format serde 'org.apache.hadoop.hive.serde2.JsonSerDe'   -- æ˜¾å¼æŒ‡å®šserde
STORED AS  TEXTFILE;   -- éšå¼æŒ‡å®šinputformatå’Œoutputformat

```





**æ–‡æœ¬æ–‡ä»¶ï¼Œæ‰éœ€è¦æ˜¾å¼æŒ‡å®š serde**

> å…¶ä»–çš„åˆ—å¼å­˜å‚¨æ–‡ä»¶ï¼ˆorcã€parquetã€rcfileï¼‰æˆ–äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆSequenceFileï¼‰ï¼Œéƒ½æœ‰å›ºå®šçš„serdeï¼Œä¸éœ€è¦æ˜¾å¼æŒ‡å®šï¼›



æ–‡æœ¬æ–‡ä»¶çš„serdeæœ‰

```sql
ROW FORMAT SERDE  'org.apache.hadoop.hive.serde2.RegexSerDe'
WITH SERDEPROPERTIES
( "input.regex" = "<regex>" )
STORED AS TEXTFILE;
```



```sql
ROW FORMAT SERDE  'org.apache.hive.hcatalog.data.JsonSerDe'
STORED AS TEXTFILE
```



```sql
CREATE TABLE my_table(a string, b string, ...)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
   "separatorChar" = "\t",
   "quoteChar"     = "'",
   "escapeChar"    = "\\"
)  
```



**ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' å¯¹åº”çš„å°±æ˜¯å¦‚ä¸‹çš„å®šä¹‰ï¼š**

```sql
ROW FORMAT SERDE  'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'   
WITH SERDEPROPERTIES (                             
  'field.delim'=',',                               
  'serialization.format'=','
  ) 
```





## 2.7 è¡¨å­˜å‚¨è·¯å¾„

```sql
  [LOCATION hdfs_path]
```

```sql
create table default.emps(
id int,
name string
);
-- å¦‚æœä¸æŒ‡å®šlocationï¼Œhiveä¹Ÿä¼šè¡¥å……ä¸€ä¸ªé»˜è®¤çš„locationï¼š  /user/hive/warehouse/emps/



create table default.emps(
id int,
name string
)
LOCATION '/aa/bb' ;
-- æŒ‡å®šäº†locationï¼Œé‚£ä¹ˆè¡¨çš„å­˜å‚¨è·¯å¾„å°±åœ¨æŒ‡å®šçš„è·¯å¾„
```



## 2.8 è¡¨çš„å±æ€§ï¼ˆè¡¨å‚æ•°ï¼‰å®šä¹‰

* è¯­æ³•

```sql
[TBLPROPERTIES (property_name=property_value, ...)]
```

* ç¤ºä¾‹1

```sql
create table default.emps(
id int,
name string
)
stored as orc

tblproperties(
   'sub_system' = 'content',   -- è‡ªå®šä¹‰çš„å±æ€§ï¼Œä¸å½±å“hiveçš„è¡Œä¸º
   'orc.compress' = 'snappy'   -- å†…éƒ¨çš„å±æ€§ï¼ŒæŒ‡å®šè¡¨çš„æ•°æ®æ–‡ä»¶çš„å‹ç¼©æ ¼å¼
);
```

* ç¤ºä¾‹2

```sql
create table default.employee_2(
id int,
name string
)
stored as orc
tblproperties(
   'sub_system' = 'content',   -- è‡ªå®šä¹‰çš„å±æ€§ï¼Œä¸å½±å“hiveçš„è¡Œä¸º
   'orc.compress' = 'snappy',   -- å†…éƒ¨çš„å±æ€§ï¼ŒæŒ‡å®šè¡¨çš„æ•°æ®æ–‡ä»¶çš„å‹ç¼©æ ¼å¼
   'auto.purge' = 'true',    -- trueåˆ™åˆ é™¤è¡¨çš„æ•°æ®ç›´æ¥æ¸…ç©ºï¼›fasleæ˜¯é»˜è®¤å€¼ï¼Œæ˜¯æ”¾å…¥å›æ”¶ç«™
   'EXTERNAL' = 'TRUE'
);


insert into employee_2 values (1,'aa'),(2,'bb'),(3,'cc');

```





***





# 3.**Hive æ•°æ®ç±»å‹**

## &#x33;**.1  åŸºæœ¬æ•°æ®ç±»å‹**

å¯¹äº Hive çš„ String ç±»å‹ç›¸å½“äºæ•°æ®åº“çš„varchar ç±»å‹ï¼Œè¯¥ç±»å‹æ˜¯ä¸€ä¸ªå¯å˜çš„å­—ç¬¦ä¸²ï¼Œä¸è¿‡å®ƒä¸èƒ½å£°æ˜å…¶ä¸­æœ€å¤šèƒ½å­˜å‚¨å¤šå°‘ä¸ªå­—ç¬¦ï¼Œç†è®ºä¸Šå®ƒå¯ä»¥å­˜å‚¨ 2GB çš„å­—ç¬¦æ•°ã€‚

## &#x33;**.2  é›†åˆæ•°æ®ç±»å‹**

Hive æœ‰ä¸‰ç§å¤æ‚æ•°æ®ç±»å‹ ARRAYã€MAP å’Œ STRUCTã€‚ARRAY å’Œ MAP ä¸ Java ä¸­çš„ Arrayå’Œ Map ç±»ä¼¼ï¼Œè€Œ STRUCT ä¸ C è¯­è¨€ä¸­çš„ Struct ç±»ä¼¼ï¼Œå®ƒå°è£…äº†ä¸€ä¸ªå‘½åå­—æ®µé›†åˆï¼Œå¤æ‚æ•°æ®ç±»å‹å…è®¸ä»»æ„å±‚æ¬¡çš„åµŒå¥—ã€‚

## &#x33;**.3 ç±»å‹è½¬åŒ–**

Hive çš„åŸå­æ•°æ®ç±»å‹æ˜¯å¯ä»¥è¿›è¡Œéšå¼è½¬æ¢çš„ï¼Œç±»ä¼¼äº Java çš„ç±»å‹è½¬æ¢ï¼Œä¾‹å¦‚æŸè¡¨è¾¾å¼ä½¿ç”¨ INT ç±»å‹ï¼ŒTINYINT ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºINT ç±»å‹ï¼Œä½†æ˜¯ Hive ä¸ä¼šè¿›è¡Œåå‘è½¬åŒ–ï¼Œä¾‹å¦‚ï¼ŒæŸè¡¨è¾¾å¼ä½¿ç”¨ TINYINT ç±»å‹ï¼ŒINT ä¸ä¼šè‡ªåŠ¨è½¬æ¢ä¸º TINYINT ç±»å‹ï¼Œå®ƒä¼šè¿”å›é”™è¯¯ï¼Œé™¤éä½¿ç”¨ CASTæ“ä½œã€‚

**éšå¼ç±»å‹è½¬æ¢è§„åˆ™ï¼š**

1. ä»»ä½•æ•´æ•°ç±»å‹éƒ½å¯ä»¥éšå¼åœ°è½¬æ¢ä¸ºä¸€ä¸ªèŒƒå›´æ›´å¹¿çš„ç±»å‹ï¼Œå¦‚ TINYINT å¯ä»¥è½¬æ¢æˆINTï¼ŒINT å¯ä»¥è½¬æ¢æˆ BIGINTã€‚

2. æ‰€æœ‰æ•´æ•°ç±»å‹ã€FLOAT å’Œ STRING ç±»å‹éƒ½å¯ä»¥éšå¼åœ°è½¬æ¢æˆ DOUBLEã€‚

3. TINYINTã€SMALLINTã€INT éƒ½å¯ä»¥è½¬æ¢ä¸º FLOATã€‚

4. BOOLEAN ç±»å‹ä¸å¯ä»¥è½¬æ¢ä¸ºä»»ä½•å…¶å®ƒçš„ç±»å‹ã€‚

**å¯ä»¥ä½¿ç”¨** **CAST** **æ“ä½œæ˜¾ç¤ºè¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢**

ä¾‹å¦‚ CAST('1' AS INT)å°†æŠŠå­—ç¬¦ä¸²'1' è½¬æ¢æˆæ•´æ•° 1ï¼›å¦‚æœå¼ºåˆ¶ç±»å‹è½¬æ¢å¤±è´¥ï¼Œå¦‚æ‰§è¡Œ CAST('X' AS INT)ï¼Œè¡¨è¾¾å¼è¿”å›ç©ºå€¼ NULL





## 3.4 mapç±»å‹ä½¿ç”¨

**ç±»å‹å®šä¹‰ï¼š  &#x20;**

```sql
å­—æ®µå  MAP<keyç±»å‹,valueç±»å‹>
```





**æ„é€ æ–¹æ³•**

```sql
map(k1,v1,k2,v2,.....)
```



**ä½¿ç”¨ç¤ºä¾‹**

```sql
create database db2;

drop table db2.complex_source;
create table db2.complex_source(
   id    int,
   name  string,
   gender string,
   scores string
)
row format delimited
fields terminated by ','
;


load data local inpath '/root/sc.txt' into table db2.complex_source;


1,zs,male,78:82:66:72
2,ls,male,88:86:68:97
3,ww,female,72:62:96:77
4,zl,female,78:82:36:57

-------------------------------------------


create table db2.complex_demo1(
    id  int,
    score_map map<string,float>
)
partitioned by (city string)
stored as orc
tblproperties(
    'orc.compress'='snappy'
);

with tmp as (
    SELECT
        id,
        split(scores,':') as arr   -- arr æ˜¯ä¸€ä¸ªæ•°ç»„ç±»å‹ ARRAY<STRING>
    FROM db2.complex_source 
)

insert into table db2.complex_demo1 PARTITION(city='SH')
SELECT
    id,
    map('è¯­æ–‡',cast(arr[0] as float),'æ•°å­¦',cast(arr[1] as float),'ç‰©ç†',cast(arr[2] as float),'åŒ–å­¦',cast(arr[3] as float)) as score_map
FROM tmp 



---mapä¸Šçš„å„ç§è¿ç®—ç¬¦å’Œå‡½æ•° ------------


select  id,score_map['è¯­æ–‡'] as scfrom complex_demo1 ;
select id,score_map['è‹±è¯­'] as sc from complex_demo1 ;   -- ä¸å­˜åœ¨å°±è¿”å›NULL

select id,map_keys(score_map) as sc from complex_demo1        -- å–mapçš„æ‰€æœ‰keyï¼Œè¿”å›æ•°ç»„
select id,map_valuess(score_map) as sc from complex_demo1 ;   -- å–mapçš„æ‰€æœ‰valueï¼Œè¿”å›æ•°ç»„
select id,size(score_map) as sc from complex_demo1 ;          -- å–mapçš„size


----é¢å¤–çš„ä¸€ä¸ªè·Ÿmapæœ‰å…³çš„å‡½æ•°--- æŠŠå­—ç¬¦ä¸²åˆ‡å‰²å¹¶å°è£…æˆmap
select str_to_map('a:1-c:2-d:3','-',':');
```







## 3.5 arrayç±»å‹ä½¿ç”¨

**æ„é€ å‡½æ•°**

```sql
array(å…ƒç´ ,å…ƒç´ ....)

select 1 as id, array(1,2,3,4) as arr;
```



**æ•°ç»„çš„è¿ç®—ç¬¦å’Œå‡½æ•°**

```sql
-- å‡è®¾æœ‰ä¸€ä¸ªå­—æ®µscores æ˜¯æ•°ç»„ç±»å‹
drop table if exists db2.complex_demo2;
create table db2.complex_demo2(
   id int,
   name string,
   scores array<decimal(2,0)>
)
stored as orc;

-- æ’å…¥æµ‹è¯•æ•°æ® --
insert into complex_demo2 
select 1, 'zs', array(80.0,90.0,60.0)
union all
select 2, 'bb', array(20.0,90.0,60.0,88.0)
union all
select 1, 'cc', array(90.0,50.0,60.0);


-- å–ç¬¬ä¸€æ¬¡è€ƒè¯•çš„æˆç»©
select  id, scores[0]  as score_0 from  db2.complex_demo2;

-- å–å„ç”Ÿçš„è€ƒè¯•æ¬¡æ•°
select id, size(scores) as cnt  from  db2.complex_demo2;

-- å–å„ç”Ÿæ˜¯å¦æœ‰60.0åˆ†çš„æˆç»©
select id, array_contains(scores,60.0) from  db2.complex_demo2;

-- å–åŒ…å«80åˆ†æˆç»©çš„å­¦ç”Ÿä¿¡æ¯
select 
*
from  db2.complex_demo2
where array_contains(scores,80.0)


-- å°†å„ç”Ÿçš„å†æ¬¡è€ƒè¯•æˆç»©æ’åº
select id, sort_array(scores) from   db2.complex_demo2;

--- 2ä¸ªè·Ÿæ•°ç»„æœ‰å…³çš„å­—ç¬¦ä¸²å‡½æ•° ----- 
select split('a:b:c',':') ;   -- å°†å­—ç¬¦ä¸²æŒ‰åˆ†éš”ç¬¦ï¼Œåˆ‡æˆæ•°ç»„
select 1 as id,concat_ws('-',array('a','b','c'));  -- å°†æ•°ç»„ä¸­çš„å…ƒç´ æ‹¼æ¥æˆå­—ç¬¦ä¸²

```





## 3.6 structç±»å‹ä½¿ç”¨

```sql

---- ç±»å‹å®šä¹‰è¯­æ³• -----------------------------------------
æŸå­—æ®µ   STRUCT<å±æ€§å:ç±»å‹,  å±æ€§å:ç±»å‹,  .....>


-------æµ‹è¯•ç”¨è¡¨ -------------------------------------
drop table if exists db2.complex_demo3;
create table db2.complex_demo3(
    id  int,
    scores  STRUCT<course_name:string, course_score:float , course_teacher:string>
)
stored as orc ;


-- åˆ©ç”¨ named_struct æ„é€ å‡½æ•° ï¼Œç”Ÿæˆæµ‹è¯•æ•°æ®  ----------------------------------------------
insert into table db2.complex_demo3 
select  1 as id, named_struct('course_name','doris','course_score',cast(80 as float),'course_teacher','æ°å“¥')
union all 
select  1 as id, named_struct('course_name','hadoop','course_score',cast(88 as float),'course_teacher','æ–‡å“¥')
union all 
select  2 as id, named_struct('course_name','hive','course_score',cast(98 as float),'course_teacher','æ–‡å“¥')
union all 
select  2 as id, named_struct('course_name','spark','course_score',cast(68 as float),'course_teacher','è¡Œå“¥')


-- å¦å¤–ä¸€ä¸ªstructæ„é€  ------------------------------------
select struct('doris',88,'è¡Œå“¥');  -- å¾—åˆ°çš„structä¸­çš„å±æ€§åä¸ºé»˜è®¤çš„  col1 ,col2 ,col3


-------- ä»structä¸Šè·å–æ•°æ®
select  scores.col1, scores.col2  from complex_demo3;

```













# 3 å¸¸ç”¨å‡½æ•°

## 3.1 å‡½æ•°æ¦‚è§ˆ

* **æ•°å­¦å‡½æ•° &#x20;**

* **å­—ç¬¦ä¸²å‡½æ•°&#x20;**

* **æ—¥æœŸæ—¶é—´å‡½æ•°**

* **é›†åˆå‡½æ•°**

* **èšåˆå‡½æ•°**

* è¡¨ç”Ÿæˆå‡½æ•°

* å…¶ä»–å‡½æ•°





## 3.2 å¿…ä¼šå‡½æ•°

### 3.2.1 æ ‡é‡å‡½æ•°ï¼ˆUDFï¼‰

#### 1 æ•°å­¦å‡½æ•°

```java
abs(-100) => 100
rand()  => 0.3240970978
ceil(3.2)  => 4 
floor(3.8) => 3
greatest(3,10,6) => 10
least(3,10,6) => 3 
round(3.56,1)  =>  3.6
```

***

#### 2 é›†åˆå‡½æ•°

```java
array_contains(æ•°ç»„,'a')  ==> å¦‚æœæ•°ç»„ä¸­åŒ…å« aï¼Œåˆ™è¿”å›trueï¼Œå¦åˆ™ false
map_keys(mapå­—æ®µï¼‰ ==> è¿”å›ä¼ å…¥çš„mapçš„æ‰€æœ‰keyï¼Œæ•°ç»„
map_values(mapå­—æ®µï¼‰  ==> è¿”å›ä¼ å…¥çš„mapçš„æ‰€æœ‰valueï¼Œæ•°ç»„
size(mapå­—æ®µ æˆ– æ•°ç»„å­—æ®µï¼‰  ==> è¿”å›é›†åˆçš„é•¿åº¦ 
```

***

#### 3 æ—¶é—´å‡½æ•°

```java
from_unixtime(10ä½é•¿æ•´æ•°,'yyyy-MM-dd HH:mm:ss')  ==> æŠŠé•¿æ•´æ•°â€œç»å¯¹æ—¶é—´â€ è½¬æˆæ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²
from_utc_timestamp(1725518648000,'GMT+8');   // å¯ä»¥æŠŠä¸€ä¸ªç»å¯¹æ—¶é—´æ ¹æ®æŒ‡å®šçš„æ—¶åŒºè½¬æˆtimestamp

// æ³¨æ„æ—¶åŒºçš„é—®é¢˜
unix_timestamp('2009-03-20', 'yyyy-MM-dd') = 1237532400
to_date('2024-09-05')  ==> å¾—åˆ°æ˜¯ä¸€ä¸ªdateç±»å‹çš„æ—¥æœŸ
datediff('2024-09-01', '2024-09-06')   ==> å¾—åˆ°æ—¥æœŸçš„å·®å€¼ï¼ˆå¤©æ•°ï¼‰
date_sub('2024-09-10',  2)   ==>  2024-09-08
date_add('2024-09-10',  2)   ==>  2024-09-12
current_date    ==>   è¿”å›å½“å‰çš„æ—¥æœŸ
date_format('2024-09-05','yyyy/MM/dd');  ==> æ ¼å¼åŒ–ä¸€ä¸ªæ—¶é—´æˆä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå¯ä»¥ä¼ å­—ç¬¦ä¸²æ—¶é—´ã€timestampã€dateç±»å‹å‚æ•°
```

***



#### 4 æ¡ä»¶å‡½æ•°

if(æ¡ä»¶ï¼Œå€¼1ï¼Œ  å€¼2 ï¼‰   ==> å¦‚æœæ¡ä»¶ä¸ºtrueï¼Œåˆ™è¿”å›å€¼1ï¼Œå¦åˆ™è¿”å›å€¼2

nvl(å€¼1ï¼Œå€¼2)   ==> å€¼1 ä¸ä¸ºnullåˆ™è¿”å› å€¼1ï¼Œå¦åˆ™è¿”å› å€¼2

COALESCE(å€¼1ï¼Œå€¼2, ......)  ==> è¿”å›ç¬¬ä¸€ä¸ªä¸ä¸ºnullçš„å€¼ï¼Œéƒ½ä¸ºnullåˆ™è¿”å›null&#x20;

case when

```sql
case  age 
    when 18 then 'é£åæ­£èŒ‚'
    when 28 then 'é¾™é©¬ç²¾ç¥'
    when 38 then 'é™ˆå¹´ä½³é…¿'
    when 48 then 'æ²‰é¦™è…Šè‚‰'
    else 'é£çƒ›æ®‹å¹´'
end


case  
    when age <=18 then 'é£åæ­£èŒ‚'
    when age <=28 then 'é¾™é©¬ç²¾ç¥'
    when age <=38 then 'é™ˆå¹´ä½³é…¿'
    when age <=48 then 'æ²‰é¦™è…Šè‚‰'
    else 'é£çƒ›æ®‹å¹´'
end
```



***

#### 5 å­—ç¬¦ä¸²å‡½æ•°

```java
split('a:b:c'  , ':' )   ==> è¿”å›æ•°ç»„:  ['a'  ,   'b'  ,  'c'  ]
```



```java
substr('foobar', 4)    => 
select substr('foobar1234567', 4 , 5) ;   ==>    bar12   
```



```java
concat('foo', 'bar')    ==>  foobar
concat_ws('-', 'foo', 'bar','car')  => foo-bar-car
concat_ws('-',array('a' ,'b' ,'c' ) )  => a-b-c
```



```java
find_in_set('ab', 'xx,yy,ab,abc,666')   =>  3
instr( 'xxyyabxx,abc,666' , 'ab')    =>   5
```



```java
select lpad( 'abc',  6,      '*');   ==>   ***abc  
select rpad('abcde',  6,   '*');  ==>    abcde*  
```



```java
ltrim('           ab')   ==>  'ab'  
rtrim('     ab          ')   ==>  '     ab'  
trim('     ab       ')  ==>  'ab'
```



ğŸ”œ  **æ­£åˆ™æŠ½å–ã€åŒ¹é…å‡½æ•°**

`select regexp_extract('abcxyyyz666uuuuu999', 'abc(.*)666(.*)', 1);   ==> xyyyz `

`select regexp_extract('sgsa18612348786sdlkg', '(\\d+)', 1);   ==>   18612348786`

```sql
ç®€å•è§£é‡Šï¼š
String regex = "^((13[0-9])|(14[5,6,7,9])|(15[^4])|(16[5,6])|(17[0-9])|(18[0-9])|(19[1,8,9]))\\d{8}$";
"[1]"ä»£è¡¨ä¸‹ä¸€ä½ä¸ºæ•°å­—å¯ä»¥æ˜¯å‡ ï¼Œ
"[0-9]"ä»£è¡¨å¯ä»¥ä¸º0-9ä¸­çš„ä¸€ä¸ªï¼Œ
"[5,7,9]"è¡¨ç¤ºå¯ä»¥æ˜¯5,7,9ä¸­çš„ä»»æ„ä¸€ä½,
[^4]è¡¨ç¤ºé™¤4ä»¥å¤–çš„ä»»ä½•ä¸€ä¸ª,
\\d{8}"ä»£è¡¨åé¢æ˜¯å¯ä»¥æ˜¯0ï½9çš„æ•°å­—ï¼Œæœ‰8ä½ã€‚
```





ğŸ”œ  J**SONæŠ½å–å‡½æ•°**

`get_json_object(string json_string, string jsonPath)`

```sql
    info  string
{"name":"zs","age":18, "order":{"oid":"od0001"} , "arr":[3,18,36]}
    

select get_json_object(info, '$.name' )   ==>    zs  
select get_json_object(info, '$.order.oid' )   ==>    od0001
select get_json_object(info,  '$.arr')   =>   [3,18,36]

select get_json_object(info,  '$.arr[1]')  =>  18


```

***



### 3.2.2 èšåˆå‡½æ•° UDAF&#x20;

ğŸ”œ `  sum/ count/ min / max / avg  `



ğŸ”œ `  collect_list / collect_set  `

```sql
-- æŠŠä¸€ç»„æ•°æ®ä¸­çš„colå­—æ®µçš„å€¼ï¼Œæ”¶é›†æˆä¸€ä¸ªæ•°ç»„è¿”å›ï¼› 

collect_set(col)  -- ä¼šå¯¹å…ƒç´ å»é‡
collect_list(col)  -- ä¸å»é‡
```

ä½¿ç”¨ç¤ºä¾‹ï¼š

```sql

+------------+-------------+-------------------+-------------+
| orders.id  | orders.amt  | orders.user_name  |  orders.dt  |
+------------+-------------+-------------------+-------------+
| 1          | 38.8        | aaa               | 2024-09-04  |
| 1          | 46.6        | aaa               | 2024-09-04  |
| 2          | 22.8        | bbb               | 2024-09-04  |
| 2          | 10.8        | bbb               | 2024-09-04  |
+------------+-------------+-------------------+-------------+

select user_name , collect_list(amt)  from orders group by user_name;

+------------+--------------+
| user_name  |     _c1      |
+------------+--------------+
| aaa        | [38.8,46.6]  |
| bbb        | [22.8,10.8]  |
+------------+--------------+
```





### 3.2.2 è¡¨ç”Ÿæˆå‡½æ•° UDTF&#x20;

**ğŸ”œ explode ç‚¸è£‚æ•°ç»„**

```sql
+-------------------+---------------------+-----------------------+
| complex_demo2.id  | complex_demo2.name  | complex_demo2.scores  |
+-------------------+---------------------+-----------------------+
| 1                 | zs                  | [80,90,60]            |
| 2                 | bb                  | [20,90,60,88]         |
| 1                 | cc                  | [90,50,60]            |
+-------------------+---------------------+-----------------------+


select 
id,name, sc  
from complex_demo2 
lateral view 
explode(scores) tmp as sc;

+-----+-------+-----+
| id  | name  | sc  |
+-----+-------+-----+
| 1   | zs    | 80  |
| 1   | zs    | 90  |
| 1   | zs    | 60  |
| 2   | bb    | 20  |
| 2   | bb    | 90  |
| 2   | bb    | 60  |
| 2   | bb    | 88  |
| 1   | cc    | 90  |
| 1   | cc    | 50  |
| 1   | cc    | 60  |
+-----+-------+-----+
```



**ğŸ”œ  explode ç‚¸è£‚map**

```sql
+-------------------+--------------------------------------------+---------------------+
| complex_demo1.id  |          complex_demo1.score_map           | complex_demo1.city  |
+-------------------+--------------------------------------------+---------------------+
| 1                 | {"è¯­æ–‡":78.0,"æ•°å­¦":82.0,"ç‰©ç†":66.0,"åŒ–å­¦":72.0}  | SH                  |
| 2                 | {"è¯­æ–‡":88.0,"æ•°å­¦":86.0,"ç‰©ç†":68.0,"åŒ–å­¦":97.0}  | SH                  |
| 3                 | {"è¯­æ–‡":72.0,"æ•°å­¦":62.0,"ç‰©ç†":96.0,"åŒ–å­¦":77.0}  | SH                  |
| 4                 | {"è¯­æ–‡":78.0,"æ•°å­¦":82.0,"ç‰©ç†":36.0,"åŒ–å­¦":57.0}  | SH                  |
+-------------------+--------------------------------------------+---------------------+


select 
id,city,course_name,course_score  
from complex_demo1 
lateral view   
explode(score_map) tmp as course_name,course_score;



+-----+-------+--------------+---------------+
| id  | city  | course_name  | course_score  |
+-----+-------+--------------+---------------+
| 1   | SH    | è¯­æ–‡           | 78.0          |
| 1   | SH    | æ•°å­¦           | 82.0          |
| 1   | SH    | ç‰©ç†           | 66.0          |
| 1   | SH    | åŒ–å­¦           | 72.0          |
| 2   | SH    | è¯­æ–‡           | 88.0          |
| 2   | SH    | æ•°å­¦           | 86.0          |
| 2   | SH    | ç‰©ç†           | 68.0          |
| 2   | SH    | åŒ–å­¦           | 97.0          |
| 3   | SH    | è¯­æ–‡           | 72.0          |
| 3   | SH    | æ•°å­¦           | 62.0          |
| 3   | SH    | ç‰©ç†           | 96.0          |
| 3   | SH    | åŒ–å­¦           | 77.0          |
| 4   | SH    | è¯­æ–‡           | 78.0          |
| 4   | SH    | æ•°å­¦           | 82.0          |
| 4   | SH    | ç‰©ç†           | 36.0          |
| 4   | SH    | åŒ–å­¦           | 57.0          |
+-----+-------+--------------+---------------+
```



**ğŸ”œ explode åº”ç”¨æ¡ˆä¾‹**

```sql
æœ‰å¦‚ä¸‹è¡¨æ ¼

create table sentences(
   sentence  string
);


insert into table sentences values 
('spark flink java hadoop hive spark flink hbase'),
('java flink kafka hadoop hive paimon flink hbase'),
('spark flink java paimon hive spark flink hbase'),
('spark hudi java hadoop hive hudi flink hbase')


-- ç»Ÿè®¡å•è¯ä¸ªæ•°
with tmp as (
select 
explode(split(sentence,' ')) as word
from sentences
)

select
word,
count(1)

from tmp 
group by word
;

```







## 3.3 è‡ªå®šä¹‰å‡½æ•°

* 1ï¼Œè¦å¯¼å…¥hiveçš„ä¾èµ–

```xml
<dependency>
    <groupId>org.apache.hive</groupId>
    <artifactId>hive-exec</artifactId>
    <version>3.1.2</version>
</dependency>
```



### 3.3.1 **æ ‡é‡å‡½æ•°çš„ä¾‹å­**

* 2ï¼Œå†™ä¸€ä¸ªjavaç±»ï¼ŒæŒ‰ç…§æ¥å£å»å®ç°å³å¯

```java
public class UDFExample_1 extends UDF {
    public String evaluate(String str) {
        return str.toUpperCase();
    }ao
}
```



* 3ï¼Œå°†ä»£ç æ‰“æˆjaråŒ…ï¼Œå¹¶ä¸Šä¼ åˆ°beelineæ‰€è¿è¡Œçš„æœºå™¨

* 4ï¼Œåœ¨beelineçš„sqlç•Œé¢ä¸‹ï¼Œç”¨å¦‚ä¸‹å‘½ä»¤æ·»åŠ jaråŒ…åˆ°ç±»è·¯å¾„å’Œjobèµ„æº

```xml
0: jdbc:hive2://doitedu01:10000> add jar /root/hive_udf-1.0-SNAPSHOT.jar;
```

* 5ï¼Œæ³¨å†Œä¸€ä¸ªsqlå‡½æ•°ï¼Œæ˜ å°„javaä¸­çš„è‡ªå®šä¹‰UDFçš„ç±»

```xml
0: jdbc:hive2://doitedu01:10000> create temporary function my_upper as 'top.doe.hive.udf.templates.old.UDFExample_1';
```

* 6, å¯ä»¥ä½¿ç”¨æ³¨å†Œå¥½çš„å‡½æ•°

```xml
select user_id,my_upper(event_id) from user_events;
```



### 3.3.2 **æ ‡é‡å‡½æ•°çš„ç»ƒä¹ **



#### 1. **éœ€æ±‚**

æ—¶é—´æˆ³ 1725524991000  ==>   2024-09-05 16:36:16.000

fun\_x(1725524991000, 10)  ==> æŠŠä¼ å…¥çš„æ—¶é—´ï¼Œå¯¹10åˆ†é’Ÿå‘ä¸‹å–æ•´    ==> 2024-09-05 16:30:00.000
fun\_x(1725524991000, 5)    ==> æŠŠä¼ å…¥çš„æ—¶é—´ï¼Œå¯¹5åˆ†é’Ÿå‘ä¸‹å–æ•´     ==> 2024-09-05 16:35:00.000
fun\_x(1725524991000, 15)  ==> æŠŠä¼ å…¥çš„æ—¶é—´ï¼Œå¯¹15åˆ†é’Ÿå‘ä¸‹å–æ•´    ==> 2024-09-05 16:30:00.000
fun\_x(1725524991000, 30)  ==> æŠŠä¼ å…¥çš„æ—¶é—´ï¼Œå¯¹30åˆ†é’Ÿå‘ä¸‹å–æ•´    ==> 2024-09-05 16:30:00.000


**è¾“å…¥å‚æ•°1ï¼š** é•¿æ•´æ•°çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’çº§ï¼‰ 13ä¸º ==> 1725524991000   // 2024-09-05 16:32:16.000
**è¾“å…¥å‚æ•°2ï¼š** æˆªæ–­é—´éš”xï¼ˆå•ä½åˆ†é’Ÿï¼‰
**è¿”å›ç»“æœï¼š** æˆªæ–­å–æ•´åçš„æ—¶é—´å­—ç¬¦ä¸²



#### 2. **ä»£ç å®ç°**

```java
package top.doe.hive.udf.templates.exec;

import org.apache.commons.lang3.time.DateFormatUtils;
import org.apache.hadoop.hive.ql.exec.UDF;

public class TimeFloor extends UDF {

    public String evaluate(Long timestamp, int unit) {
        // 1725524991000
        // 5
        int tmp = unit*60*1000;
        long floorTime = (timestamp / tmp) * tmp;

        return DateFormatUtils.format(floorTime, "yyyy-MM-dd HH:mm:ss");
    }

}
```





### 3.3.3 èšåˆå‡½æ•°çš„ä¾‹å­

```java
package top.doe.hive.udf.templates.exec;

import org.apache.hadoop.hive.ql.exec.UDAF;
import org.apache.hadoop.hive.ql.exec.UDAFEvaluator;

public class MyAvg extends UDAF {

    // è¿™æ˜¯UDAFçš„è®¡ç®—é€»è¾‘å°è£…ç±»
    public static class AggEvaluator implements UDAFEvaluator {
        // è‡ªå®šä¹‰çš„ç´¯åŠ å™¨
        Agg agg;

        // æ„é€ æ–¹æ³•ä¸­ï¼Œä¸€å®šè¦å¯¹ç´¯åŠ å™¨è¿›è¡Œåˆå§‹åŒ–ï¼šå¯ä»¥é€šè¿‡è°ƒç”¨init()æ¥è¿›è¡Œ
        public AggEvaluator() {
            super();
            init();
        }

        // åˆå§‹åŒ–ï¼Œé‡ç‚¹æ˜¯åˆå§‹åŒ–ç´¯åŠ å™¨
        @Override
        public void init() {
            agg = new Agg();
        }


        // ä»åŸå§‹è¾“å…¥æ•°æ®è·å¾—æ•°æ®åè®¡ç®—
        public boolean iterate(Double value) {
            if (value != null) {
                agg.sum += value;
                agg.cnt += 1;
            }
            return true;
        }


        // æ¯æ¬¡å±€éƒ¨èšåˆå®Œæˆæ—¶è°ƒç”¨ï¼Œä»¥è¾“å‡ºå±€éƒ¨èšåˆçš„ç»“æœ
        // è¿™ä¸ªç»“æœä¼šäº¤ç»™å…¨å±€èšåˆé˜¶æ®µä½œä¸ºè¾“å…¥
        public Agg terminatePartial() {
            return agg;
        }


        // å…¨å±€èšåˆé€»è¾‘
        // æ¯ä¸€ä¸ªè¾“å…¥æ•°æ®ï¼Œå°±æ˜¯å±€éƒ¨èšåˆé˜¶æ®µæ‰€è¾“å‡ºçš„ä¸€ä¸ªç»“æœæ•°æ®
        public boolean merge(Agg partialAgg) {
            if (partialAgg != null) {
                agg.sum += partialAgg.sum;
                agg.cnt += partialAgg.cnt;
            }

            return true;
        }


        // å…¨å±€èšåˆå®Œæˆåï¼Œç”¨äºè¾“å‡ºæœ€ç»ˆè¿”å›ç»“æœçš„é€»è¾‘
        public Double terminate() {
            return agg.sum/agg.cnt;
        }


        /**
         *  è‡ªå®šä¹‰çš„ç´¯åŠ å™¨ç±»
         */
        public static class Agg {
            double sum;
            int cnt;
        }

    }
}
```





### 3.3.4 èšåˆå‡½æ•°çš„ç»ƒä¹ 

#### 1. éœ€æ±‚è¯´æ˜

æ¯”å¦‚ï¼Œæœ‰å¦‚ä¸‹æ•°æ®

```sql
uid,province,city,event_id
1,å±±ä¸œ,æµå—,event2
1,å±±ä¸œ,æµå—,event2
2,å±±ä¸œ,æµå—,event2
3,å±±ä¸œ,æµå—,event2
4,å±±ä¸œ,æµå—,event2
5,å±±ä¸œ,æµå—,event2
6,å±±ä¸œ,é’å²›,event2
6,å±±ä¸œ,é’å²›,event2
7,å±±ä¸œ,é’å²›,event2
7,å±±ä¸œ,é’å²›,event2
2,å±±ä¸œ,é’å²›,event2
2,å±±ä¸œ,é’å²›,event2
8,æ±Ÿè‹,å—äº¬,event2
8,æ±Ÿè‹,å—äº¬,event2
9,æ±Ÿè‹,å—äº¬,event2
9,æ±Ÿè‹,å—äº¬,event2
2,æ±Ÿè‹,å—äº¬,event2
3,æ±Ÿè‹,è‹å·,event2
3,æ±Ÿè‹,è‹å·,event2
2,æ±Ÿè‹,è‹å·,event2


-- æ˜ç»†æ•°æ®è¡¨
create table bmtest(
   id       int,
   province string,
   city     string,
   event    string   
)
row format delimited
fields terminated by ',';

load data local inpath '/root/bm.txt' into table bmtest;


-- ç»†ç²’åº¦èšåˆè¡¨
create table bm_agg(
   province string,
   city     string,
   ids_bm   binary 
)
row format delimited
fields terminated by ',';


-- æ³¨å†Œå‡½æ•°
create temporary function int2bm as 'top.doe.hive.udf.templates.exec.IntGroup2BitmapUDAF';
create temporary function bmagg as 'top.doe.hive.udf.templates.exec.BitmapAggUDAF';
create temporary function bmprint as 'top.doe.hive.udf.templates.exec.BitmapElementsUDF';
create temporary function bmcount as 'top.doe.hive.udf.templates.exec.BitmapCountUDF';


-- æŒ‰çœå¸‚  ç»†ç²’åº¦èšåˆ  ----------
insert into table bm_agg 
select  province
        ,city
        ,int2bm(id) as ids_bm
from bmtest
group by province,city


-- æŒ‰çœèšåˆ
select
    province,
    -- bmagg(ids_bm) as ids_bm,
    bmprint(bmagg(ids_bm))  as ids,
    bmcount(bmagg(ids_bm)) as cnt
from bm_agg
group by province

```



éœ€è¦è®¡ç®—ï¼Œ

1. æ¯ä¸ªçœæ¯ä¸ªå¸‚ä¸­ï¼Œå‘ç”Ÿäº†event2çš„äººæ•°

```sql
select
    province,
    city,
    count(distinct uid) as ucnt 

from ttt
group by province,city

---------------------
å±±ä¸œ,æµå—,5
å±±ä¸œ,é’å²›,3
æ±Ÿè‹,å—äº¬,3
æ±Ÿè‹,è‹å·,2
```



* æ¯ä¸ªçœ,å‘ç”Ÿäº†event2çš„äººæ•°

â›”ï¸ğŸ” â˜¢ï¸ å¦‚æœç›´æ¥ä» çœå¸‚ ç²’åº¦ç»“æœï¼Œæ±‚å’Œï¼Œå¾—åˆ°çš„ç»“æœæ˜¯ä¸æ­£ç¡®çš„ï¼ï¼

```sql
--- å¯ä»¥è¿™ä¹ˆåš
åœ¨èšåˆ çœå¸‚ç²’åº¦ç»“æœæ—¶ï¼Œä¸è¦æŠŠå…·ä½“çš„äººæ•°ä½œä¸ºèšåˆç»“æœï¼Œè€Œæ˜¯æŠŠ ä¸€ä¸ª bitmap ä½œä¸ºèšåˆç»“æœ
å±±ä¸œ,  æµå—,  [0 1 1 1 1 1 0 0 0 0 0....]
å±±ä¸œ,  é’å²›,  [0 0 1 0 0 0 1 1 0 0 0....]

select
    province,
    city,
    bitmap_agg(uid) as ub

from ttt
group province,city



-- æœ‰äº†ä¸Šé¢çš„ç»“æœï¼Œå°±å¯ä»¥åŸºäºä¸Šé¢çš„çœå¸‚ç²’åº¦çš„ç»“æœï¼Œç›´æ¥èšåˆå‡ºçœç²’åº¦çš„ç»“æœ
å±±ä¸œ,[01111111000....]


```



**æœ€ç»ˆï¼Œå°±æ˜¯è¦å¼€å‘ä¸€ä¸ªè‡ªå®šä¹‰çš„UDAF ï¼ˆåˆ†ç»„èšåˆï¼‰**

* è¾“å…¥å‚æ•°ï¼šuid  ï¼ˆæ•´æ•°ï¼‰

* è¿”å›ç»“æœï¼š bitmapå¯¹è±¡åºåˆ—åŒ–æˆå­—èŠ‚æ•°ç»„  ï¼ˆsqlä¸­å¯¹åº”çš„ç±»å‹æ˜¯ binaryï¼‰

* ä½¿ç”¨æ–¹æ³•ï¼š

```sql
select
  province,
  city,
  bitmap_agg(uid) as bm
from ttt 
group by province,city
```



#### 2. ä»£ç å®ç°

```java










```



èšåˆå‡½æ•°2ï¼š&#x20;

è¾“å…¥ï¼šbitmapçš„åºåˆ—åŒ–å­—èŠ‚

è¾“å‡ºï¼šä¸€ç»„bitmapçš„èšåˆç»“æœå­—èŠ‚





### 3.3.5 hiveä¸­çš„UDAFçš„æ³¨æ„äº‹é¡¹

åœ¨è‡ªå®šä¹‰çš„UDAFä¸­ï¼Œæˆ‘ä»¬çš„æ•°æ®è¾“å…¥è¾“å‡ºç±»å‹ï¼Œå¯ä»¥æœ‰

* åŸºæœ¬ç±»å‹

* Writableç±»å‹

* è‡ªå®šä¹‰ç±»å‹ï¼ˆè‡ªå®šä¹‰ç±»å‹ä¸­ï¼Œä¸èƒ½æŒæœ‰ æ•°ç»„ç±»å‹ çš„æˆå‘˜ï¼‰

collect\_list  &#x20;

collect\_set



# 4 hiveä¸­çš„ç‰¹åˆ«æŸ¥è¯¢

## 4.1 sort by æ’åº

sort by æ˜¯åœ¨æ¯ä¸ªreduceå†…å¯¹æ•°æ®æ’åºï¼š

* æ¯ä¸ªreduceçš„è¾“å‡ºç»“æœæ˜¯æœ‰åºçš„

* å…¨å±€åˆ™ä¸ä¸€å®šæœ‰åº

```sql

-- æ•°æ®é‡å¤ªå°æ—¶ï¼Œhiveè‡ªåŠ¨ä¼°ç®—å‡ºçš„reduceå¹¶è¡Œåº¦ä¸º1ï¼Œsort byåˆ™çœ‹ä¸åˆ°æ•ˆæœäº†
set mapreduce.job.reduces = 3ï¼›

select  *
from student 
sort by score desc;

```



order  by æ˜¯å…¨å±€æœ‰åºï¼Œä½†æ˜¯åº•å±‚çš„mapreduce**åªèƒ½æœ‰ä¸€ä¸ªreduceå¹¶è¡Œåº¦**







## 4.2 åˆ†æ¡¶æŸ¥è¯¢

* distribute by ..... sort by ....

* cluster by ....

```java
hive (default)> set mapreduce.job.reduces=3;
hive (default)> insert overwrite local directory 
'/opt/module/data/distribute-result' 
select * from emp 
distribute by deptno 
sort by empno desc;
```

å½“ distribute by å’Œ sorts by å­—æ®µç›¸åŒæ—¶ï¼Œå¯ä»¥ä½¿ç”¨ cluster by æ–¹å¼ã€‚

cluster by é™¤äº†å…·æœ‰ distribute by çš„åŠŸèƒ½å¤–è¿˜å…¼å…· sort by çš„åŠŸèƒ½ã€‚ä½†æ˜¯æ’åºåªèƒ½æ˜¯å‡åº

æ’åºï¼Œä¸èƒ½æŒ‡å®šæ’åºè§„åˆ™ä¸º ASC æˆ–è€… DESCã€‚

```sql
-- ä¸‹é¢çš„è¯­å¥å½¢æˆçš„ç»“æœè§„å¾‹ï¼š
-- reduceæ•°é‡å‡è®¾ä¸º4 ï¼Œé‚£ä¹ˆæŸ¥è¯¢çš„ç»“æœæ–‡ä»¶å°†æœ‰4ä¸ª
-- æ¯ä¸ªæ–‡ä»¶ä¸­æ˜¯deptno å¯¹4 hashæ•£åˆ—çš„ç»“æœ
-- åœ¨æ¯ä¸ªæ–‡ä»¶ä¸­ï¼Œæ•°æ®æ˜¯æŒ‰ageæœ‰åºçš„
hive (default)> set mapreduce.job.reduces=4;
hive (default)> insert overwrite local direcotry '/root/distribute/'
              > select * from emp distribute by deptno sort by age;
```

![](images/image-1.png)



> **å¦‚æœdistribute by å’Œsort byçš„å­—æ®µç›¸åŒï¼Œä¸”æ˜¯å‡åºæ’åºï¼Œåˆ™å¯ä»¥ç®€å†™æˆ cluster by**

```sql
-- ä»¥ä¸‹ä¸¤ç§å†™æ³•ç­‰ä»·
hive (default)> select * from emp cluster by deptno;
hive (default)> select * from emp distribute by deptno sort by deptno asc;

```



## 4.3 æŠ½æ ·æŸ¥è¯¢

### æ¡¶æŠ½æ ·  --  ä»¥æ¡¶çš„æ–¹å¼

```java
SELECT *
FROM source TABLESAMPLE(BUCKET 3 OUT OF 32 ON rand()) s;

TABLESAMPLE(BUCKET 3 OUT OF 16 ON id)
TABLESAMPLE(BUCKET 3 OUT OF 64 ON id)
```

å¦‚æœè¡¨çš„åˆ†æ¡¶æ•°ä¸º32ï¼Œåˆ™&#x20;

* BUCKET 3 OUT OF 16 ON id æŠ½å–çš„æ˜¯  32/16 = 2æ¡¶ï¼Œ ç›®æ ‡æ¡¶ä¸º æ¡¶3å’Œæ¡¶19

* BUCKET 3 OUT OF 64 ON id æŠ½å–çš„æ˜¯  32/64=1/2æ¡¶ï¼Œç›®æ ‡æ¡¶ä¸º æ¡¶3





### blockæŠ½æ ·

```java
set hive.sample.seednumber=<INTEGER>;

SELECT *
FROM source TABLESAMPLE(0.1 PERCENT) s;

SELECT *
FROM source TABLESAMPLE(300M) s;
```

æŠ½å–éšæœºçš„blockæ•°æ®ï¼›

* å¦‚æœæŒ‡å®šçš„æ•°æ®é‡å°äºæ–‡ä»¶blocksizeï¼Œå°±ä¼šæŠ½åˆ°æ•´ä¸ªblock

* å¦‚æœæŒ‡å®šçš„æ•°æ®é‡è¶…è¿‡æ–‡ä»¶blockszieï¼Œåˆ™ä¼šéšæœºæŒ‘å¤šä¸ªblockè¿”å›ï¼›





### è¡ŒæŠ½æ ·

```java
SELECT * FROM source TABLESAMPLE(10 ROWS);
```

**æ­¤æ—¶ï¼Œhiveä¸ä¼šä½¿ç”¨combineFileInputFormatï¼Œä¸”ä¼šå¯¹æ¯ä¸ªsplitæŠ½å–æŒ‡å®šè¡Œæ•°**

**æ‰€ä»¥ï¼Œå…·ä½“æŠ½å–çš„è¡Œæ•°ï¼Œä¼šæ ¹æ®è¡¨çš„splitæ•°é‡è€Œå˜åŒ–**





### æŠ½æ ·æ¡ˆä¾‹

æŠ½æ ·ç”¨æ¥å¹²å˜›çš„ï¼Ÿ

åœ¨å¯¹å…¨è¡¨è¿›è¡ŒæŸä¸ªç»Ÿè®¡ä»£ä»·å¤ªå¤§æ—¶ï¼Œå¯ä»¥å…ˆæŠ½æ ·ï¼Œç„¶åå¯¹æŠ½æ ·çš„æ•°æ®è¿›è¡Œç»Ÿè®¡ï¼›

```sql
with tmp as (
    select
      aid
    from events
    tablesample(1000 rows)
)


-- aidå­—æ®µæ¯ä¸ªå€¼çš„ä¸ªæ•°
-- aidå­—æ®µæ¯ä¸ªå€¼çš„å æ¯”
select
   aid,      -- aidçš„æŸä¸ªå€¼
   cnt,      -- aidçš„æŸä¸ªå€¼çš„æ€»è¡Œæ•°
   total,    -- æŠ½æ ·æ•°æ®æ€»è¡Œæ•°
   round(cnt/total,2) as ratio
from (
    select  
      count(1) as total
    from tmp 
) a 
join 
(
    select
        aid,
        count(1) as cnt
    from tmp
    group by aid 
) b 
order by cnt desc 
limit 10
```









# é™„å½•ï¼š hiveçš„IDEAæœ¬åœ°è°ƒè¯•

**ä¾èµ–**

```sql
<dependency>
    <groupId>org.apache.hive</groupId>
    <artifactId>hive-cli</artifactId>
    <version>3.1.2</version>
    <exclusions>
        <exclusion>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-*</artifactId>
        </exclusion>
        <exclusion>
            <artifactId>hadoop-hdfs</artifactId>
            <groupId>org.apache.hadoop</groupId>
        </exclusion>
    </exclusions>
    <scope>provided</scope>
</dependency>

<dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-client</artifactId>
    <version>3.1.0</version>
    <scope>provided</scope>
</dependency>
```

**æµ‹è¯•ä»£ç **

```java
public class MyUDFIntegrationTest {
    private Driver driver;

    @Before
    public void setup() throws HiveException {
        HiveConf conf = new HiveConf();
        conf.set("fs.defaultFS","hdfs://doitedu01:8020/");
        conf.set("hive.metastore.uris","thrift://doitedu01:9083");

        SessionState.start(new SessionState(conf));
        driver = new Driver(conf);

        // æ³¨å†Œè‡ªå®šä¹‰å‡½æ•°
        FunctionRegistry.registerTemporaryUDF("bmagg", BitmapUDAF.class);

    }

    @Test
    public void testUDFInHive() throws HiveException {
        String query = "SELECT bmagg(id) FROM student";
        CommandProcessorResponse run = driver.run(query);

    }
}
```
