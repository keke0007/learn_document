# ä¸­é—´ä»¶åŸºç¡€ä¸é«˜çº§å¼€å‘å­¦ä¹ æŒ‡å—

## ğŸ“š é¡¹ç›®æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†å®Œæ•´çš„ä¸­é—´ä»¶å¼€å‘å­¦ä¹ èµ„æºï¼Œæ¶µç›– Redisã€MongoDBã€InfluxDBã€Elasticsearchã€RabbitMQã€RocketMQã€Kafkaã€MinIO ç­‰ä¸»æµä¸­é—´ä»¶ï¼ŒåŒ…æ‹¬åŸºç¡€æ¦‚å¿µã€é«˜çº§ç‰¹æ€§ã€å®æˆ˜æ¡ˆä¾‹å’ŒéªŒè¯æ•°æ®ï¼Œå¸®åŠ©ä½ ç³»ç»ŸæŒæ¡ä¸­é—´ä»¶å¼€å‘æŠ€æœ¯ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
midware/
â”œâ”€â”€ GUIDE.md                     # æœ¬æŒ‡å—æ–‡æ¡£ï¼ˆå¿«é€Ÿå…¥é—¨ï¼‰
â”œâ”€â”€ README.md                    # ä¸­é—´ä»¶çŸ¥è¯†ç‚¹æ€»è§ˆï¼ˆè¯¦ç»†æ–‡æ¡£ï¼‰
â”œâ”€â”€ cases/                       # å®æˆ˜æ¡ˆä¾‹ç›®å½•
â”‚   â”œâ”€â”€ redis.md                # æ¡ˆä¾‹1ï¼šRedis
â”‚   â”œâ”€â”€ mongodb.md               # æ¡ˆä¾‹2ï¼šMongoDB
â”‚   â”œâ”€â”€ influxdb.md             # æ¡ˆä¾‹3ï¼šInfluxDB
â”‚   â”œâ”€â”€ elasticsearch.md        # æ¡ˆä¾‹4ï¼šElasticsearch
â”‚   â”œâ”€â”€ rabbitmq.md             # æ¡ˆä¾‹5ï¼šRabbitMQ
â”‚   â”œâ”€â”€ rocketmq.md             # æ¡ˆä¾‹6ï¼šRocketMQ
â”‚   â”œâ”€â”€ kafka.md                # æ¡ˆä¾‹7ï¼šKafka
â”‚   â””â”€â”€ minio.md                # æ¡ˆä¾‹8ï¼šMinIO
â”œâ”€â”€ data/                        # éªŒè¯æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ redis_data.json         # Redis æ•°æ®ç¤ºä¾‹
â”‚   â”œâ”€â”€ mongodb_data.json       # MongoDB æ•°æ®ç¤ºä¾‹
â”‚   â”œâ”€â”€ elasticsearch_data.json # Elasticsearch æ•°æ®ç¤ºä¾‹
â”‚   â””â”€â”€ performance_test.txt    # æ€§èƒ½æµ‹è¯•æ•°æ®
â””â”€â”€ scripts/                     # ä»£ç ç¤ºä¾‹ç›®å½•
    â”œâ”€â”€ redis_demo.py           # Redis ç¤ºä¾‹
    â”œâ”€â”€ mongodb_demo.py          # MongoDB ç¤ºä¾‹
    â”œâ”€â”€ elasticsearch_demo.py    # Elasticsearch ç¤ºä¾‹
    â”œâ”€â”€ rabbitmq_demo.py         # RabbitMQ ç¤ºä¾‹
    â””â”€â”€ kafka_demo.py           # Kafka ç¤ºä¾‹
```

---

## ğŸ¯ å­¦ä¹ è·¯å¾„

### é˜¶æ®µä¸€ï¼šç¼“å­˜ä¸­é—´ä»¶ï¼ˆ7-10å¤©ï¼‰
1. **Redis**
   - åŸºç¡€æ•°æ®ç»“æ„
   - æŒä¹…åŒ–æœºåˆ¶
   - ä¸»ä»å¤åˆ¶
   - å“¨å…µæ¨¡å¼
   - é›†ç¾¤æ¨¡å¼
   - é«˜çº§ç‰¹æ€§

### é˜¶æ®µäºŒï¼šNoSQL æ•°æ®åº“ï¼ˆ10-14å¤©ï¼‰
1. **MongoDB**
   - æ–‡æ¡£æ¨¡å‹
   - ç´¢å¼•ä¼˜åŒ–
   - èšåˆç®¡é“
   - å‰¯æœ¬é›†
   - åˆ†ç‰‡é›†ç¾¤

2. **InfluxDB**
   - æ—¶åºæ•°æ®æ¨¡å‹
   - æ•°æ®ä¿ç•™ç­–ç•¥
   - è¿ç»­æŸ¥è¯¢
   - é›†ç¾¤éƒ¨ç½²

### é˜¶æ®µä¸‰ï¼šæœç´¢å¼•æ“ï¼ˆ7-10å¤©ï¼‰
1. **Elasticsearch**
   - å€’æ’ç´¢å¼•
   - æŸ¥è¯¢ DSL
   - èšåˆåˆ†æ
   - é›†ç¾¤ç®¡ç†

### é˜¶æ®µå››ï¼šæ¶ˆæ¯é˜Ÿåˆ—ï¼ˆ14-21å¤©ï¼‰
1. **RabbitMQ**
   - äº¤æ¢æœºç±»å‹
   - é˜Ÿåˆ—å’Œç»‘å®š
   - æ¶ˆæ¯ç¡®è®¤
   - é›†ç¾¤æ¨¡å¼

2. **RocketMQ**
   - Topic å’Œ Queue
   - é¡ºåºæ¶ˆæ¯
   - äº‹åŠ¡æ¶ˆæ¯
   - é›†ç¾¤éƒ¨ç½²

3. **Kafka**
   - Topic å’Œ Partition
   - Producer å’Œ Consumer
   - æ¶ˆæ¯å­˜å‚¨
   - é›†ç¾¤ç®¡ç†

### é˜¶æ®µäº”ï¼šå¯¹è±¡å­˜å‚¨ï¼ˆ5-7å¤©ï¼‰
1. **MinIO**
   - å¯¹è±¡å­˜å‚¨æ¦‚å¿µ
   - Bucket ç®¡ç†
   - è®¿é—®æ§åˆ¶
   - åˆ†å¸ƒå¼éƒ¨ç½²

---

## ğŸ“– æ ¸å¿ƒçŸ¥è¯†ç‚¹è¯¦è§£

### 1. Redis

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
Redis æ˜¯é«˜æ€§èƒ½çš„å†…å­˜æ•°æ®åº“ï¼Œæ”¯æŒå¤šç§æ•°æ®ç»“æ„ï¼Œå¸¸ç”¨äºç¼“å­˜ã€ä¼šè¯å­˜å‚¨ã€æ¶ˆæ¯é˜Ÿåˆ—ç­‰åœºæ™¯ã€‚

#### æ ¸å¿ƒç‰¹æ€§

**æ•°æ®ç»“æ„**
- Stringï¼šå­—ç¬¦ä¸²
- Hashï¼šå“ˆå¸Œè¡¨
- Listï¼šåˆ—è¡¨
- Setï¼šé›†åˆ
- Sorted Setï¼šæœ‰åºé›†åˆ
- Bitmapï¼šä½å›¾
- HyperLogLogï¼šåŸºæ•°ç»Ÿè®¡
- Streamï¼šæµ

**æŒä¹…åŒ–**
- RDBï¼šå¿«ç…§æŒä¹…åŒ–
- AOFï¼šè¿½åŠ æ–‡ä»¶æŒä¹…åŒ–

**é«˜å¯ç”¨**
- ä¸»ä»å¤åˆ¶
- å“¨å…µæ¨¡å¼
- é›†ç¾¤æ¨¡å¼

#### æ¡ˆä¾‹ä»£ç 

```python
# redis_demo.py
import redis

# è¿æ¥ Redis
r = redis.Redis(host='localhost', port=6379, db=0)

# String æ“ä½œ
r.set('name', 'Redis')
print(r.get('name'))  # b'Redis'

# Hash æ“ä½œ
r.hset('user:1', 'name', 'Alice')
r.hset('user:1', 'age', '25')
print(r.hgetall('user:1'))  # {b'name': b'Alice', b'age': b'25'}

# List æ“ä½œ
r.lpush('list', 'item1', 'item2', 'item3')
print(r.lrange('list', 0, -1))  # [b'item3', b'item2', b'item1']

# Set æ“ä½œ
r.sadd('set', 'member1', 'member2')
print(r.smembers('set'))  # {b'member1', b'member2'}

# Sorted Set æ“ä½œ
r.zadd('sorted_set', {'member1': 10, 'member2': 20})
print(r.zrange('sorted_set', 0, -1, withscores=True))
```

---

### 2. MongoDB

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
MongoDB æ˜¯æ–‡æ¡£å‹ NoSQL æ•°æ®åº“ï¼Œä½¿ç”¨ BSON æ ¼å¼å­˜å‚¨æ•°æ®ï¼Œæ”¯æŒçµæ´»çš„æ–‡æ¡£æ¨¡å‹ã€‚

#### æ ¸å¿ƒç‰¹æ€§

**æ–‡æ¡£æ¨¡å‹**
- é›†åˆï¼ˆCollectionï¼‰
- æ–‡æ¡£ï¼ˆDocumentï¼‰
- å­—æ®µï¼ˆFieldï¼‰

**æŸ¥è¯¢æ“ä½œ**
- åŸºæœ¬æŸ¥è¯¢
- æ¡ä»¶æŸ¥è¯¢
- èšåˆç®¡é“
- ç´¢å¼•ä¼˜åŒ–

**é«˜å¯ç”¨**
- å‰¯æœ¬é›†
- åˆ†ç‰‡é›†ç¾¤

#### æ¡ˆä¾‹ä»£ç 

```python
# mongodb_demo.py
from pymongo import MongoClient
from pymongo import ASCENDING, DESCENDING

# è¿æ¥ MongoDB
client = MongoClient('mongodb://localhost:27017/')
db = client['mydb']
collection = db['users']

# æ’å…¥æ–‡æ¡£
user = {
    'name': 'Alice',
    'age': 25,
    'email': 'alice@example.com',
    'tags': ['developer', 'python']
}
result = collection.insert_one(user)
print(f"Inserted ID: {result.inserted_id}")

# æŸ¥è¯¢æ–‡æ¡£
user = collection.find_one({'name': 'Alice'})
print(user)

# æ›´æ–°æ–‡æ¡£
collection.update_one(
    {'name': 'Alice'},
    {'$set': {'age': 26}}
)

# èšåˆæŸ¥è¯¢
pipeline = [
    {'$match': {'age': {'$gte': 25}}},
    {'$group': {'_id': '$department', 'avg_age': {'$avg': '$age'}}},
    {'$sort': {'avg_age': -1}}
]
results = collection.aggregate(pipeline)
for result in results:
    print(result)
```

---

### 3. InfluxDB

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
InfluxDB æ˜¯æ—¶åºæ•°æ®åº“ï¼Œä¸“é—¨ç”¨äºå­˜å‚¨å’ŒæŸ¥è¯¢æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¸¸ç”¨äºç›‘æ§ã€IoT ç­‰åœºæ™¯ã€‚

#### æ ¸å¿ƒæ¦‚å¿µ

**æ•°æ®æ¨¡å‹**
- Databaseï¼šæ•°æ®åº“
- Measurementï¼šè¡¨
- Tagï¼šæ ‡ç­¾ï¼ˆç´¢å¼•ï¼‰
- Fieldï¼šå­—æ®µï¼ˆå€¼ï¼‰
- Timestampï¼šæ—¶é—´æˆ³

**ä¿ç•™ç­–ç•¥**
- Retention Policyï¼šæ•°æ®ä¿ç•™ç­–ç•¥
- Continuous Queryï¼šè¿ç»­æŸ¥è¯¢

#### æ¡ˆä¾‹ä»£ç 

```python
# influxdb_demo.py
from influxdb import InfluxDBClient

# è¿æ¥ InfluxDB
client = InfluxDBClient(host='localhost', port=8086, database='mydb')

# å†™å…¥æ•°æ®
json_body = [
    {
        "measurement": "cpu_usage",
        "tags": {
            "host": "server01",
            "region": "us-west"
        },
        "time": "2024-01-26T10:00:00Z",
        "fields": {
            "value": 0.64
        }
    }
]
client.write_points(json_body)

# æŸ¥è¯¢æ•°æ®
result = client.query('SELECT * FROM cpu_usage WHERE time > now() - 1h')
for point in result.get_points():
    print(point)
```

---

### 4. Elasticsearch

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
Elasticsearch æ˜¯åˆ†å¸ƒå¼æœç´¢å¼•æ“ï¼ŒåŸºäº Luceneï¼Œæ”¯æŒå…¨æ–‡æœç´¢ã€å®æ—¶åˆ†æç­‰ã€‚

#### æ ¸å¿ƒæ¦‚å¿µ

**ç´¢å¼•ç»“æ„**
- Indexï¼šç´¢å¼•
- Typeï¼šç±»å‹ï¼ˆå·²åºŸå¼ƒï¼‰
- Documentï¼šæ–‡æ¡£
- Fieldï¼šå­—æ®µ

**æŸ¥è¯¢ DSL**
- Match Queryï¼šåŒ¹é…æŸ¥è¯¢
- Term Queryï¼šç²¾ç¡®æŸ¥è¯¢
- Range Queryï¼šèŒƒå›´æŸ¥è¯¢
- Aggregationï¼šèšåˆåˆ†æ

#### æ¡ˆä¾‹ä»£ç 

```python
# elasticsearch_demo.py
from elasticsearch import Elasticsearch

# è¿æ¥ Elasticsearch
es = Elasticsearch(['localhost:9200'])

# åˆ›å»ºç´¢å¼•
index_body = {
    "mappings": {
        "properties": {
            "title": {"type": "text"},
            "content": {"type": "text"},
            "created_at": {"type": "date"}
        }
    }
}
es.indices.create(index='articles', body=index_body)

# ç´¢å¼•æ–‡æ¡£
doc = {
    'title': 'Elasticsearch Guide',
    'content': 'This is a guide to Elasticsearch',
    'created_at': '2024-01-26'
}
es.index(index='articles', id=1, body=doc)

# æœç´¢æ–‡æ¡£
query = {
    "query": {
        "match": {
            "title": "Elasticsearch"
        }
    }
}
results = es.search(index='articles', body=query)
for hit in results['hits']['hits']:
    print(hit['_source'])
```

---

### 5. RabbitMQ

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
RabbitMQ æ˜¯æ¶ˆæ¯é˜Ÿåˆ—ä¸­é—´ä»¶ï¼ŒåŸºäº AMQP åè®®ï¼Œæ”¯æŒå¤šç§æ¶ˆæ¯æ¨¡å¼ã€‚

#### æ ¸å¿ƒæ¦‚å¿µ

**äº¤æ¢æœºç±»å‹**
- Directï¼šç›´æ¥äº¤æ¢æœº
- Topicï¼šä¸»é¢˜äº¤æ¢æœº
- Fanoutï¼šæ‰‡å‡ºäº¤æ¢æœº
- Headersï¼šå¤´äº¤æ¢æœº

**æ¶ˆæ¯ç¡®è®¤**
- ç”Ÿäº§è€…ç¡®è®¤
- æ¶ˆè´¹è€…ç¡®è®¤
- æ¶ˆæ¯æŒä¹…åŒ–

#### æ¡ˆä¾‹ä»£ç 

```python
# rabbitmq_demo.py
import pika

# è¿æ¥ RabbitMQ
connection = pika.BlockingConnection(
    pika.ConnectionParameters('localhost')
)
channel = connection.channel()

# å£°æ˜é˜Ÿåˆ—
channel.queue_declare(queue='hello', durable=True)

# å‘é€æ¶ˆæ¯
channel.basic_publish(
    exchange='',
    routing_key='hello',
    body='Hello World!',
    properties=pika.BasicProperties(
        delivery_mode=2,  # æ¶ˆæ¯æŒä¹…åŒ–
    )
)

# æ¶ˆè´¹æ¶ˆæ¯
def callback(ch, method, properties, body):
    print(f"Received: {body}")
    ch.basic_ack(delivery_tag=method.delivery_tag)

channel.basic_consume(
    queue='hello',
    on_message_callback=callback,
    auto_ack=False
)
channel.start_consuming()
```

---

### 6. RocketMQ

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
RocketMQ æ˜¯é˜¿é‡Œå·´å·´å¼€æºçš„åˆ†å¸ƒå¼æ¶ˆæ¯ä¸­é—´ä»¶ï¼Œæ”¯æŒé¡ºåºæ¶ˆæ¯ã€äº‹åŠ¡æ¶ˆæ¯ç­‰é«˜çº§ç‰¹æ€§ã€‚

#### æ ¸å¿ƒæ¦‚å¿µ

**æ¶ˆæ¯æ¨¡å‹**
- Topicï¼šä¸»é¢˜
- Queueï¼šé˜Ÿåˆ—
- Producerï¼šç”Ÿäº§è€…
- Consumerï¼šæ¶ˆè´¹è€…

**æ¶ˆæ¯ç±»å‹**
- æ™®é€šæ¶ˆæ¯
- é¡ºåºæ¶ˆæ¯
- äº‹åŠ¡æ¶ˆæ¯
- å»¶æ—¶æ¶ˆæ¯

#### æ¡ˆä¾‹ä»£ç 

```python
# rocketmq_demo.py
from rocketmq.client import Producer, Message

# åˆ›å»ºç”Ÿäº§è€…
producer = Producer('ProducerGroup')
producer.set_name_server_address('localhost:9876')
producer.start()

# å‘é€æ¶ˆæ¯
msg = Message('TopicTest', 'Hello RocketMQ'.encode('utf-8'))
result = producer.send_sync(msg)
print(f"Send result: {result.status}")

# åˆ›å»ºæ¶ˆè´¹è€…
from rocketmq.client import PushConsumer, ConsumeStatus

def on_message(msg):
    print(f"Received: {msg.body.decode('utf-8')}")
    return ConsumeStatus.CONSUME_SUCCESS

consumer = PushConsumer('ConsumerGroup')
consumer.set_name_server_address('localhost:9876')
consumer.subscribe('TopicTest', '*')
consumer.register_message_listener(on_message)
consumer.start()
```

---

### 7. Kafka

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
Kafka æ˜¯åˆ†å¸ƒå¼æµå¤„ç†å¹³å°ï¼Œæ”¯æŒé«˜ååé‡çš„æ¶ˆæ¯å‘å¸ƒå’Œè®¢é˜…ã€‚

#### æ ¸å¿ƒæ¦‚å¿µ

**æ¶ˆæ¯æ¨¡å‹**
- Topicï¼šä¸»é¢˜
- Partitionï¼šåˆ†åŒº
- Producerï¼šç”Ÿäº§è€…
- Consumerï¼šæ¶ˆè´¹è€…
- Consumer Groupï¼šæ¶ˆè´¹è€…ç»„

**æ¶ˆæ¯å­˜å‚¨**
- é¡ºåºå†™å…¥
- åˆ†æ®µå­˜å‚¨
- ç´¢å¼•æ–‡ä»¶

#### æ¡ˆä¾‹ä»£ç 

```python
# kafka_demo.py
from kafka import KafkaProducer, KafkaConsumer
import json

# åˆ›å»ºç”Ÿäº§è€…
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# å‘é€æ¶ˆæ¯
producer.send('test-topic', {'key': 'value'})
producer.flush()

# åˆ›å»ºæ¶ˆè´¹è€…
consumer = KafkaConsumer(
    'test-topic',
    bootstrap_servers=['localhost:9092'],
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

# æ¶ˆè´¹æ¶ˆæ¯
for message in consumer:
    print(f"Received: {message.value}")
```

---

### 8. MinIO

#### çŸ¥è¯†ç‚¹æ¦‚è¿°
MinIO æ˜¯å¯¹è±¡å­˜å‚¨æœåŠ¡å™¨ï¼Œå…¼å®¹ Amazon S3 APIï¼Œæ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²ã€‚

#### æ ¸å¿ƒæ¦‚å¿µ

**å¯¹è±¡å­˜å‚¨**
- Bucketï¼šå­˜å‚¨æ¡¶
- Objectï¼šå¯¹è±¡
- Keyï¼šå¯¹è±¡é”®
- Metadataï¼šå…ƒæ•°æ®

**è®¿é—®æ§åˆ¶**
- Access Keyï¼šè®¿é—®å¯†é’¥
- Secret Keyï¼šç§˜å¯†å¯†é’¥
- Policyï¼šç­–ç•¥

#### æ¡ˆä¾‹ä»£ç 

```python
# minio_demo.py
from minio import Minio
from minio.error import S3Error

# è¿æ¥ MinIO
client = Minio(
    'localhost:9000',
    access_key='minioadmin',
    secret_key='minioadmin',
    secure=False
)

# åˆ›å»ºå­˜å‚¨æ¡¶
bucket_name = 'my-bucket'
if not client.bucket_exists(bucket_name):
    client.make_bucket(bucket_name)

# ä¸Šä¼ å¯¹è±¡
client.fput_object(
    bucket_name,
    'my-object',
    '/path/to/local/file.txt'
)

# ä¸‹è½½å¯¹è±¡
client.fget_object(
    bucket_name,
    'my-object',
    '/path/to/download/file.txt'
)

# åˆ—å‡ºå¯¹è±¡
objects = client.list_objects(bucket_name, recursive=True)
for obj in objects:
    print(obj.object_name)
```

---

## ğŸ“Š é¢è¯•é‡ç‚¹æ€»ç»“

### é«˜é¢‘é¢è¯•é¢˜

1. **Redis**
   - æ•°æ®ç»“æ„å’Œä½¿ç”¨åœºæ™¯
   - æŒä¹…åŒ–æœºåˆ¶
   - ä¸»ä»å¤åˆ¶å’Œå“¨å…µ
   - ç¼“å­˜ç©¿é€ã€å‡»ç©¿ã€é›ªå´©

2. **MongoDB**
   - æ–‡æ¡£æ¨¡å‹è®¾è®¡
   - ç´¢å¼•ä¼˜åŒ–
   - èšåˆç®¡é“
   - å‰¯æœ¬é›†å’Œåˆ†ç‰‡

3. **Elasticsearch**
   - å€’æ’ç´¢å¼•åŸç†
   - æŸ¥è¯¢ DSL
   - èšåˆåˆ†æ
   - é›†ç¾¤ç®¡ç†

4. **æ¶ˆæ¯é˜Ÿåˆ—**
   - RabbitMQ vs RocketMQ vs Kafka
   - æ¶ˆæ¯å¯é æ€§ä¿è¯
   - é¡ºåºæ¶ˆæ¯
   - äº‹åŠ¡æ¶ˆæ¯

5. **InfluxDB**
   - æ—¶åºæ•°æ®æ¨¡å‹
   - æ•°æ®ä¿ç•™ç­–ç•¥
   - è¿ç»­æŸ¥è¯¢

6. **MinIO**
   - å¯¹è±¡å­˜å‚¨æ¦‚å¿µ
   - S3 å…¼å®¹æ€§
   - åˆ†å¸ƒå¼éƒ¨ç½²

### å­¦ä¹ å»ºè®®

1. **ç†è®ºä¸å®è·µç»“åˆ**
   - ç†è§£åŸç†åï¼Œé€šè¿‡ä»£ç éªŒè¯
   - æ­å»ºå®éªŒç¯å¢ƒç»ƒä¹ 

2. **å¾ªåºæ¸è¿›**
   - å…ˆæŒæ¡åŸºç¡€ï¼Œå†æ·±å…¥é«˜çº§ç‰¹æ€§
   - æ¯ä¸ªçŸ¥è¯†ç‚¹éƒ½è¦æœ‰ä»£ç ç¤ºä¾‹

3. **æŒç»­ç»ƒä¹ **
   - å®šæœŸå›é¡¾çŸ¥è¯†ç‚¹
   - å‚ä¸å®é™…é¡¹ç›®å®è·µ
   - å…³æ³¨ä¸­é—´ä»¶æ›´æ–°

4. **é¢è¯•å‡†å¤‡**
   - å‡†å¤‡é¡¹ç›®ç»éªŒæè¿°
   - å‡†å¤‡æŠ€æœ¯éš¾ç‚¹å’Œè§£å†³æ–¹æ¡ˆ
   - å‡†å¤‡æ€§èƒ½ä¼˜åŒ–æ¡ˆä¾‹

---

## ğŸ”§ å·¥å…·æ¨è

### å¼€å‘å·¥å…·
- **IDE**ï¼šIntelliJ IDEAã€VS Codeã€PyCharm
- **å®¢æˆ·ç«¯å·¥å…·**ï¼š
  - Redisï¼šRedis Desktop Managerã€Another Redis Desktop Manager
  - MongoDBï¼šMongoDB Compass
  - Elasticsearchï¼šKibanaã€Elasticsearch Head
  - RabbitMQï¼šRabbitMQ Management UI
  - Kafkaï¼šKafka Toolã€Kafka Manager

### ç›‘æ§å·¥å…·
- **Prometheus**ï¼šç›‘æ§æŒ‡æ ‡
- **Grafana**ï¼šå¯è§†åŒ–é¢æ¿
- **ELK Stack**ï¼šæ—¥å¿—åˆ†æ

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
1. **Redis**ï¼šhttps://redis.io/documentation
2. **MongoDB**ï¼šhttps://docs.mongodb.com/
3. **InfluxDB**ï¼šhttps://docs.influxdata.com/influxdb/
4. **Elasticsearch**ï¼šhttps://www.elastic.co/guide/en/elasticsearch/reference/
5. **RabbitMQ**ï¼šhttps://www.rabbitmq.com/documentation.html
6. **RocketMQ**ï¼šhttps://rocketmq.apache.org/docs/
7. **Kafka**ï¼šhttps://kafka.apache.org/documentation/
8. **MinIO**ï¼šhttps://docs.min.io/

---

## âœ… å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£ Redis æ•°æ®ç»“æ„å’ŒæŒä¹…åŒ–
- [ ] æŒæ¡ MongoDB æ–‡æ¡£æ¨¡å‹å’ŒæŸ¥è¯¢
- [ ] ç†Ÿæ‚‰ InfluxDB æ—¶åºæ•°æ®æ¨¡å‹
- [ ] ç†è§£ Elasticsearch ç´¢å¼•å’ŒæŸ¥è¯¢
- [ ] æŒæ¡ RabbitMQ æ¶ˆæ¯æ¨¡å¼
- [ ] ç†Ÿæ‚‰ RocketMQ é«˜çº§ç‰¹æ€§
- [ ] ç†è§£ Kafka æ¶ˆæ¯å­˜å‚¨æœºåˆ¶
- [ ] æŒæ¡ MinIO å¯¹è±¡å­˜å‚¨
- [ ] å…·å¤‡å®é™…é¡¹ç›®ç»éªŒ
- [ ] äº†è§£æ€§èƒ½ä¼˜åŒ–æ–¹æ³•

---

**æœ€åæ›´æ–°ï¼š2026-01-26**
